[{"categories":null,"content":"让思维更聚焦，让生活更高效","date":"2023-04-21","objectID":"/20230421-7-ways-to-stay-focused/","tags":["work"],"title":"提升专注力的七种方法","uri":"/20230421-7-ways-to-stay-focused/"},{"categories":null,"content":"第一，把手机放在看不见的地方：手机已成为现代生活中最大的分心来源。为确保专注力，可以关闭工作用即时通讯软件、退出群聊、取关公众号、卸载容易分心的 APP。通过将手机放在看不见的地方或设置勿扰模式，有助于减少干扰。 第二，寻找一个不易受到干扰和分心的环境：安静、舒适的环境有助于提高专注力。因此，选择图书馆、自习室或安静的咖啡馆进行学习或工作。在家里，可以选择无电视的客厅或书房，避免在卧室或躺在床上学习。 第三，列出分心物清单：在开始工作或学习之前，列出可能导致分心的事物，如电视、游戏、聊天等。意识到这些干扰因素，有助于在工作或学习时保持专注。 第四，想想现在做的事情是否值得消耗注意力：在投入精力之前，评估任务的重要性。分清优先级，考虑投入产出比和任务边界，集中注意力在重要且紧急的事情上。对于长期不做的事情，可以考虑委托给别人或机器，或者干脆不做。 第五，阅读前喝点儿咖啡：适量喝咖啡可以提神醒脑，帮助保持清醒。注意饮用时间和剂量，以免导致失眠。早上喝一杯咖啡，午睡后再喝一杯，既提神又有助于提高新陈代谢。 第六，准备一支笔：在阅读或学习时，手边准备一支笔，以便随时记录笔记、划重点或想到新的想法。没有笔也没关系，可以使用电脑编辑器或 iOS 的提醒事项软件记录想法，避免因寻找笔而分心。 第七，觉知自己走神：在工作或学习过程中，可能会不自觉地走神。根据情况采取相应措施。如果是专注力初学者，需要将注意力拉回；若是心流状态高手，分心可能是因为疲劳，此时需要的是适当休息，例如散步或冥想等。 ","date":"2023-04-21","objectID":"/20230421-7-ways-to-stay-focused/:0:0","tags":["work"],"title":"提升专注力的七种方法","uri":"/20230421-7-ways-to-stay-focused/"},{"categories":null,"content":"为什么 JSON 需要转义？ [TOC] 适合人群：入门级 ","date":"2021-01-05","objectID":"/json-and-escaping/:0:0","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":null,"content":"JSON 和 JSON 转义 21 世纪初，Douglas Crockford 寻找一种简便的数据交换格式，能够在服务器之间交换数据。当时通用的数据交换语言是 XML，但是 Douglas Crockford 觉得 XML 的生成和解析都太麻烦，所以他提出了一种简化格式，也就是 JSON。 JSON 其结构形如 {\"云原生\":\"Kubernetes\"}，可以很直观的使用字符串表示对象或数据结构。对象或数据结构使用序列化接口转换成 JSON 字符串，比如 Golang 中的json.Marshal接口。 你可能会有这样的疑问：既然 JSON 字符串结构简单，为什么不直接使用字符串拼接的方式，而是要使用 JSON 序列化接口呢？ 结果显而易见：JSON 序列化接口会一并将数据中的特殊字符进行转义，防止其破坏 JSON 原有结构。比如数据中含有双引号\"特殊字符，序列化接口便会对双引号进行转义，最终结果类似于{\"云原生\":\"\\\"Kubernetes\\\"\"}，否则，该场景下直接拼接的字符串会非法。 ","date":"2021-01-05","objectID":"/json-and-escaping/:1:0","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":null,"content":"JSON 转义 许多程序设计语言把双引号字符（\"）用作字符串的分界符。反斜线（\\）转义字符提供了两种方式来把双引号字符置入字符串中，或者是使用转义序列\\\"表示单个的\"字符本身，而不是作为字符串分界符；或者是直接开始字符\"的 16 进制编码值的转义序列\\x22来表示\"，也可以使用 8 进制编码值的转义序列，如\\042。 在 Python 中，下面的代码将会产生语法错误 print \"Cloud Navite \"Hello World!\".\"; 而另一段 Python 代码则会产生符合预期的结果 print \"Cloud Navite \\\"Hello World!\\\".\"; 在 JSON 中，也是如此：当使用 json 接口解析字符串{\"云原生\":\"\"Kubernetes\"\"}时会报错，而解析经过转义的 JSON 字符串{\"云原生\":\"\\\"Kubernetes\\\"\"}则会解析成功。 JSON 转义机制如下图： JSON 中字符串针对于特殊字符需要 JSON 转义，它使用反斜杠\\进行转义 JSON 序列包括“\\\\、\\\"、\\/、\\b、\\f、\\n、\\r、\\t，或者 Unicode16 进制转义字符（比如\\uD83D\\uDE02) JSON 字符串默认为 UTF-8 编码。可以通过观察前四个八位字节中的空值模式来确定一个八位字节流是 UTF-8、UTF-16（BE 或 LE）还是 UTF-32（BE 或 LE） ","date":"2021-01-05","objectID":"/json-and-escaping/:1:1","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":null,"content":"JSON 语法 在讲具体案例之前，复习一下 JSON 语法，忘记的可以翻阅该章节。 JSON 语法简单来说就是四条： 数据在名称/值对中 数据由逗号分隔 花括号保存对象 方括号保存数组 声明：以下使用的对象均来自于以下内容 { \"virtualeNB\":[ {\"virteNBName\":\"virt1\", \"virteNBNum\":5, \"begineNBID\":0, \"beginCtlPort\":6000, \"beginDataPort\":7000, \"virtIPNum\":5}, {\"virteNBName\":\"virt2\", \"virteNBNum\":10, \"begineNBID\":10, \"beginCtlPort\":6000, \"beginDataPort\":7000, \"virtIPNum\":10} ], \"eRAN\":[ {\"eRANName\":\"eNB1\", \"eRANID\":3002, \"ctlPort\":36412, \"dataPort\":2152}, {\"eRANName\":\"eNB2\", \"eRANID\":10000, \"ctlPort\":36412, \"dataPort\":2152} ] } 1. JSON 名称/值对 JSON 数据的书写格式是：名称：值，这样的一对。即名称在前，该名称的值在冒号后面。例如： \"virteNBName\":\"virt1\" 这里的名称是\"virteNBName\"，值是\"virt1\"，他们均是字符串 名称和值得类型可以有以下几种： 数字（整数或浮点数） 字符串（在双引号中） 逻辑值（true 或 false） 数组（在方括号中） 对象（在花括号中） null 2. JSON 数据由逗号分隔 譬如： \"virteNBName\":\"virt1\", \"virteNBNum\":5, \"begineNBID\":0这几个对象之间就是使用逗号分隔。 数组内的对象之间当然也是要用逗号分隔。只要是对象之间，分隔就是用逗号,。但是，要注意，对象结束的时候，不要加逗号。数组内也是，例如： [ {\"eRANName\":\"eNB1\", \"eRANID\":3002, \"ctlPort\":36412, \"dataPort\":2152}, {\"eRANName\":\"eNB2\", \"eRANID\":10000, \"ctlPort\":36412, \"dataPort\":2152}, ] 上面这个就是错误的，因为在数组中，两个对象之间需要逗号，但是到这个数组末尾了，不需要加逗号了。 3. JSON 花括号保存对象 对象可以包含多个名称/值对，如： {\"eRANName\":\"eNB1\", \"eRANID\":3002, \"ctlPort\":36412, \"dataPort\":2152} 这一点也容易理解，与这条 JavaScript 语句等价： \"eRANName\" = \"eNB1\" \"eRANID\" = 3002 \"ctlPort\" = 36412 \"dataPort\" = 2152 4. JSON 方括号保存数组 数组可包含多个对象： \"eRAN\":[ {\"eRANName\":\"eNB1\", \"eRANID\":3002, \"ctlPort\":36412, \"dataPort\":2152}, {\"eRANName\":\"eNB2\", \"eRANID\":10000, \"ctlPort\":36412, \"dataPort\":2152} ] 在上面的例子中，对象 “eRAN” 是包含 2 个对象的数组。每个对象代表一条基站的记录。 上面四条规则，就是 JSON 格式的所有内容。 ","date":"2021-01-05","objectID":"/json-and-escaping/:1:2","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":null,"content":"案例 ","date":"2021-01-05","objectID":"/json-and-escaping/:2:0","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":null,"content":"一个由特殊字符导致 JSON 格式的 Nginx 访问日志/日志系统的 BUG 访问日志 access_log：Nginx 会将每个客户端访问其本身的请求以日志的形式记录到指定的日志文件里，以供分析用户的浏览或请求行为，或者可以用于快速分析故障所在。此功能由 ngx_http_log_module 模块负责。 在 Nginx 文件中，访问日志 access.log 配置形如下文的格式： log_format main '$remote_addr [$time_local] \"$request\" ' '$status $bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main buffer=32k; logs/access.log 指定访问日志路径 log_format 定义访问日志格式 buffer=32k 是日志缓冲区大小 访问日志 access_log 其通过格式化输出 nginx 变量以及拼接字符串的方式打印日志。 在云原生时代，Nginx 运维的最佳实践之一就是将 Nginx 访问日志采用 EFK 架构 (Elasticsearch+Filebeat+Kibana)，通过收集和管理访问日志，提供统一的检索功能，这样做不仅可以提高诊断效率，而且可以全面了解系统情况，避免被动事后救火。 通常，为了方便分析，会将 Nginx 访问日志输出为 JSON 字符串，其配置如下： log_format main '{\"remote_addr\":\"$remote_addr\",\"time_local\":\"$time_local\",\"request\":\"$request\",' '\"status\":\"$status\",\"bytes_sent\":\"$bytes_sent\",\"http_referer\":\"$http_referer\",' '\"http_user_agent\":\"$http_user_agent\",\"http_x_forwarded_for\":\"$http_x_forwarded_for\"}'; access_log logs/access.log main buffer=32k; 乍一看，这样的配置没什么问题。但再深入思考，生成 JSON 字符串的标准做法是调用 JSON 序列化接口，而 Nginx 访问日志是直接格式化拼接字符串，故一旦访问日志中出现特殊字符（比如双引号\"），就会导致整行访问日志解析出错，影响接下来的日志分析系统对访问日志的数据查找、服务诊断和数据分析。 为了解决 JSON 转义的问题，Nginx 在 1.11.8 版本中给日志格式 log_format 新增了序列化配置 escape=json，其格式为： Syntax: log_format name [escape=default|json|none] string ...; Default: log_format combined \"...\"; Context: http 当配置为 escape=json 时，JSON 字符串中所有不允许的字符都将被转义： \"和/字符被转义为/\"和// 值小于 32 的字符被转义“\\n”, “\\r”, “\\t”, “\\b”, “\\f”, or “\\u00XX” 所以，正确的 log_format 配置为 log_format main escape=json '{\"remote_addr\":\"$remote_addr\",\"time_local\":\"$time_local\",\"request\":\"$request\",' '\"status\":\"$status\",\"bytes_sent\":\"$bytes_sent\",\"http_referer\":\"$http_referer\",' '\"http_user_agent\":\"$http_user_agent\",\"http_x_forwarded_for\":\"$http_x_forwarded_for\"}'; 当然，因为 JSON 转义导致的 BUG 不止这一个，近期遇到的另一个 BUG 也是因为前人实现的代码实现不规范，其逻辑是将收到的请求以字符串拼接的方式构造 JSON 串，导致一旦请求中带有双引号\"或其他特殊字符，就必定出现 BUG。 ","date":"2021-01-05","objectID":"/json-and-escaping/:2:1","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":null,"content":"JSON 与其他格式的比较 ","date":"2021-01-05","objectID":"/json-and-escaping/:3:0","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":null,"content":"JSON vs XML JSON 与 XML 最大的不同在于 XML 是一个完整的标记语言，而 JSON 不是。这使得 XML 在程序判读上需要比较多的功夫。主要的原因在于 XML 的设计理念与 JSON 不同。XML 利用标记语言的特性提供了绝佳的延展性（如 XPath），在数据存储，扩展及高级检索方面具备对 JSON 的优势，而 JSON 则由于比 XML 更加小巧，以及浏览器的内建快速解析支持，使得其更适用于网络数据传输领域。 从转义角度来看，XML 标签名不能包含任何字符!\"#$%\u0026'()*+,/;\u003c=\u003e?@[\\]^{|}~，也不能包含空格字符，不能以-、.或数字数字开头，而 JSON 键可以（引号和反斜杠必须转义）。 ","date":"2021-01-05","objectID":"/json-and-escaping/:3:1","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":null,"content":"JSON vs YAML JSON 格式简单易上手，但没有了 YAML 的一目了然，尤其是 JSON 数据很长的时候，会让人陷入繁琐复杂的数据节点查找中。通常我会使用在线 JSON 格式化工具，来更方便的对 JSON 数据进行节点查找和解析。 个人认为，YAML 几乎将 JSON 秒成渣渣，这里直接引用 YAML 官方文档 关于 YAML 的总结： YAML 的可读性好 YAML 和脚本语言的交互性好 YAML 使用实现语言的数据类型 YAML 有一个一致的信息模型 YAML 易于实现 YAML 可以基于流来处理 YAML 表达能力强，扩展性好 YAML 可以写注释 ","date":"2021-01-05","objectID":"/json-and-escaping/:3:2","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":null,"content":"There Is One More Thing 从结构上看，不仅仅是 JSON、YAML、XML，大部分或者所有的数据（data）最终都可以分解成三种类型： 第一种类型是标量（scalar），也就是一个单独的字符串（string）或数字（numbers），比如\"云原生\"这个单独的词。 第二种类型是序列（sequence），也就是若干个相关的数据按照一定顺序并列在一起，又叫做数组（array）或列表（List），比如[\"Kubernetes\", \"Istio\"]。 第三种类型是映射（mapping），也就是一个名/值对（Name/value），即数据有一个名称，还有一个与之相对应的值，这又称作散列（hash）或字典（dictionary），比如\"CloudNative\": \"Kubernetes\"。 ","date":"2021-01-05","objectID":"/json-and-escaping/:4:0","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":null,"content":"参考 JSON 官网 JSON 维基百科 数据类型和 Json 格式–阮一峰 YAML Ain’t Markup Language (YAML™) Version 1.1 World Wide Web Consortium 自己最初了解 JSON 时总结的一篇文章 ","date":"2021-01-05","objectID":"/json-and-escaping/:5:0","tags":["code"],"title":"为什么 JSON 需要转义","uri":"/json-and-escaping/"},{"categories":["essay"],"content":"《欧洲绘画五百年》参观有感","date":"2020-12-28","objectID":"/history-of-western-painting/","tags":["blog","essay"],"title":"《欧洲绘画五百年》参观有感","uri":"/history-of-western-painting/"},{"categories":["essay"],"content":" 生日的时候飞去成都参观成都博物馆正在展出的西方绘画史，庆祝生日，感慨良多，记录下自己的感想 画作主题受限于思想。被神学/基督教控制的文艺复兴初期，画作只能是神祗，颜料也尽显奢华；随着西方文艺复兴给人们带来的思想解放，大家的主题不再局限于神祗，更注重于人本身，比如充满情趣的田园画，肖像画/自画像；随着科技进步，颜料可以带出门，派生出风景画派；大家生活水平提升，画画不再是一定是谋生手段（为达官贵人画肖像画可以填饱肚子），可以画自己想画的东西，主题百花齐放。 吃饱了才能搞艺术。西方文艺复兴以来其艺术中心的变迁：意大利/罗马（文艺复兴）-\u003e荷兰黄金时代（荷兰小画派）-\u003e巴黎-\u003e西欧以及美国百花齐放百家争鸣，其实也对应的是西方十四世纪以来的经济中心的变迁：从东西罗马纵横捭阖，荷兰/西班牙黄金一代/大航海时代，法兰西帝国和日不落帝国，第一次和第二次工业革命英国和美国变为世界的两极。 一个人的成功不仅要靠自身的努力和天分，还要考虑历史的进程以及找对师父。要有天分，很多大家早在十几岁二十几岁其绘画天赋便锋芒毕露；要靠个人努力，大部分在展上的画师无一不是耗费了巨大的精力投入在艺术创作中，年少成名的画师也是十一二岁便要在画师家里当学徒，兢兢业业；要站在巨人的肩膀上，要师从名师/大家，名画家的师父往往也很有名，自学成才的很少，比如高更（月亮与六便士的主角）。 画作充满美感。个人艺术细胞不足，对于艺术性的感受就是，不论是端庄严谨的教会画、轻松愉快的田园画、栩栩如生的肖像画和风景画、百花齐放百家争鸣的现实主义、浪漫主义、象征主义画作，都很美。在场看跟在网上或书上看的感觉完全不一样。 ","date":"2020-12-28","objectID":"/history-of-western-painting/:0:0","tags":["blog","essay"],"title":"《欧洲绘画五百年》参观有感","uri":"/history-of-western-painting/"},{"categories":["essay"],"content":"参考链接 欧洲绘画五百年丨高更：被画画拐上“歧路”，却抵达了艺术的神坛 ","date":"2020-12-28","objectID":"/history-of-western-painting/:1:0","tags":["blog","essay"],"title":"《欧洲绘画五百年》参观有感","uri":"/history-of-western-painting/"},{"categories":null,"content":"从 nginx 热更新聊一聊 Golang 中的热更新 静态语言在服务器编程时都会遇到这样的问题：如何保证已有的连接服务不中断同时又升级版本？ 最近花了点时间看了下 nginx 热更新代码流程，想了下结合之前的经验一并总结下热更新 ","date":"2020-12-28","objectID":"/server-hot-update/:0:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"热更新是什么？ 举个例子，你现在在坐卡车，卡车开到了 150KM/H 然后，有个轮胎，爆了 然后，司机说，你就直接换吧，我不停车。你小心点换 嗯。就这个意思 ","date":"2020-12-28","objectID":"/server-hot-update/:1:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"网关中的热更新 服务程序热更新这个问题在层 7 网关中尤其严重，网关中承载着大量的请求，包括 HTTP/HTTPS 短连接、HTTP/HTTPS 长连接、甚至是 websocket 这种超长连接（websocket 通常连接时间会很长，十几分钟到几天不等）。服务进程热更新是非常有必要的。 网关作为一个基础组件，需要保证高可用，是很难将其先停下来再更新的； 有人说可以使用负载均衡将需要更新的组件先隔离，再停机更新，但是如果是一个很小的集群没有负载均衡呢，又或者这样手动一台一台升级也着实麻烦，部分情况下就算隔离了也不过是不会有新的连接过来，旧的连接/请求依旧需要处理完成，否则就会造成部分服务不可用 不过实际上线上操作是集群隔离加热更新一起操作 ","date":"2020-12-28","objectID":"/server-hot-update/:2:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"nginx 热更新 (Upgrading Executable on the Fly) nginx [engine x] 是 Igor Sysoev 编写的一个 HTTP 和反向代理服务器，另外它也可以作为邮件代理服务器。 它已经在众多流量很大的俄罗斯网站上使用了很长时间，这些网站包括 Yandex、Mail.Ru、VKontakte，以及 Rambler。据 Netcraft 统计，在 2012 年 8 月份，世界上最繁忙的网站中有 11.48%使用 Nginx 作为其服务器或者代理服务器。 NginX 采用 Master/Worker 的多进程模型，Master 进程负责整个 NginX 进程的管理。Nginx 的模块化、热更新、Http 处理流程、日志等机制都非常经典。这里将会简要介绍一下热更新的机制 ","date":"2020-12-28","objectID":"/server-hot-update/:3:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"nginx 热升级流程 步骤 1、升级 nginx 二进制文件，需要先将新的 nginx 可执行文件替换原有旧的 nginx 文件，然后给 nginx master 进程发送 USR2 信号，告知其开始升级可执行文件；nginx master 进程会将老的 pid 文件增加。oldbin 后缀，然后拉起新的 master 和 worker 进程，并写入新的 master 进程的 pid。 UID PID PPID C STIME TTY TIME CMD root 4584 1 0 Oct17 ? 00:00:00 nginx: master process /usr/local/apigw/apigw_nginx/nginx root 12936 4584 0 Oct26 ? 00:03:24 nginx: worker process root 12937 4584 0 Oct26 ? 00:00:04 nginx: worker process root 12938 4584 0 Oct26 ? 00:00:04 nginx: worker process root 23692 4584 0 21:28 ? 00:00:00 nginx: master process /usr/local/apigw/apigw_nginx/nginx root 23693 23692 3 21:28 ? 00:00:00 nginx: worker process root 23694 23692 3 21:28 ? 00:00:00 nginx: worker process root 23695 23692 3 21:28 ? 00:00:00 nginx: worker process 步骤 2、在此之后，所有工作进程（包括旧进程和新进程）将会继续接受请求。这时候，需要发送 WINCH 信号给 nginx master 进程，master 进程将会向 worker 进程发送消息，告知其需要进行 graceful shutdown，worker 进程会在连接处理完之后进行退出。 UID PID PPID C STIME TTY TIME CMD root 4584 1 0 Oct17 ? 00:00:00 nginx: master process /usr/local/apigw/apigw_nginx/nginx root 12936 4584 0 Oct26 ? 00:03:24 nginx: worker process root 12937 4584 0 Oct26 ? 00:00:04 nginx: worker process root 12938 4584 0 Oct26 ? 00:00:04 nginx: worker process root 23692 4584 0 21:28 ? 00:00:00 nginx: master process /usr/local/apigw/apigw_nginx/nginx #若旧的 worker 进程还需要处理连接，则 worker 进程不会立即退出，需要待消息处理完后再退出 步骤 3、经过一段时间之后，将会只会有新的 worker 进程处理新的连接。 注意，旧 master 进程并不会关闭它的 listen socket；因为如果出问题后，需要回滚，master 进程需要法重新启动它的 worker 进程。 步骤 4、如果升级成功，则可以向旧 master 进程发送 QUIT 信号，停止老的 master 进程；如果新的 master 进程（意外）退出，那么旧 master 进程将会去掉自己的 pid 文件的。oldbin 后缀。 ","date":"2020-12-28","objectID":"/server-hot-update/:3:1","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"nginx 热更新相关信号 master 进程相关信号 USR2 升级可执行文件 WINCH 优雅停止 worker 进程 QUIT 优雅停止 master 进程 worker 进程相关信号 TERM, INT 快速退出进程 QUIT 优雅停止进程 ","date":"2020-12-28","objectID":"/server-hot-update/:3:2","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"nginx 相关代码走读 1、USR2 流程 master 收到 USR2 信号后，会拉起新的 master nginx 进程； 新的 master 进程拉起新的 worker 进程； 最终，老的 worker 进程和新的 worker 进程共用一个 listen socket，接受连接 若打开了 REUSEPORT 开关，则 socket 继承情况会有些区别，感兴趣的可以自行翻看代码 2、WINCH 流程 master 进程收到 WINCH 信号后，会给各个 worker 进程发送 QUIT 信号，让其优雅退出；master 进程并不再处理新的连接。 worker graceful shutdown 流程，关闭 listen socket，不再处理新的连接；待已有连接处理完后，清理连接，退出进程。 3、QUIT 流程 master graceful shutdown 流程，没什么好说的 ","date":"2020-12-28","objectID":"/server-hot-update/:3:3","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"nginx 升级过程中若出现问题如何回滚？ ","date":"2020-12-28","objectID":"/server-hot-update/:3:4","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"nginx 热升级 QA 1、如何防止多次可执行文件触发热更新？ 相关代码 ngx_signal_handler --\u003e case ngx_signal_value(NGX_CHANGEBIN_SIGNAL): if (ngx_getppid() == ngx_parent || ngx_new_binary \u003e 0) { /* * Ignore the signal in the new binary if its parent is * not changed, i.e. the old binary's process is still * running. Or ignore the signal in the old binary's * process if the new binary's process is already running. */ action = \", ignoring\"; ignore = 1; break; } ngx_change_binary = 1; action = \", changing binary\"; break; 若老的 nginx 还在，nginx 无法进行热更新二进制文件 2、nginx 升级过程中，发现新的可执行文件出现问题该如何回滚？ a、向旧 master 进程发送 HUP 信号。旧进程将启动新的 worker 进程，而且不会重新读取配置。之后，通过向新的主 master 进程发送 QUIT 信号，可以优雅地关闭新的 master 和 worker 进程。 b、将 TERM 信号发送到新的 master 进程，然后新的 master 进程将向其 worker 进程发送一条消息，让它们立即退出，这种退出不是 graceful shutdown。当新的 master 进程退出时，旧的 master 进程将启动新的 worker 进程。 c、如果新的进程没有退出，则应该向它们发送终止 KILL 信号。当新的 master 进程退出时，旧的 master 进程将启动新的工作进程。 3、什么是 graceful shutdown 本文中的 graceful shutdown 是指 server 不再处理新的连接，但是进程不会立即退出，待所有连接断开后再退出进程。 ","date":"2020-12-28","objectID":"/server-hot-update/:3:5","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"总结一下个人在 nginx 二进制文件热升级时用的命令 cd /usr/local/nginx cp nginx nginx_bak mv /data/nginx/nginx ./nginx #需要使用 mv 来更新二进制文件 ./nginx -t #尝试启动，查看其加载配置文件等初始化功能是否正常 netstat -anp | grep -E \"80|443\" | grep nginx #检查连接状态 kill -USR2 `cat /usr/local/nginx/nginx.pid` #升级 nginx 可执行文件，此时会有两组 nginx master 和 worker 进程 kill -WINCH `cat /usr/local/nginx/nginx.pid.oldbin` #新的可执行文件启动 ok，且能够正常处理数据流，告知老的 master 进程去通知其 worker 进程进行优雅退出 ... kill -QUIT `cat /usr/local/nginx/nginx.pid.oldbin` #待所有的老的 nginx worker 进程优雅退出后（处理完连接），停止老的 master 进程 TODO：nginx 还会有依赖的 so 文件的热升级–其实更应该属于后台进程的 so 文件热升级流程，我在使用它的时候也踩过坑–主要原因还是操作不规范，对 so 其加载运行原理不够熟悉导致 ","date":"2020-12-28","objectID":"/server-hot-update/:3:6","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"热升级 实际上，静态语言后端 server 有一套固定的热升级（单进程）流程，其基本流程如下： 若需要支持热升级的是多进程，那么 nginx 的热升级过程是最值得参考的 1、通过调用 fork/exec 启动新的版本的进程， 2、子进程调用接口获取从父进程继承的 socket 文件描述符重新监听 socket 3、在此过程中，不会对用户请求造成任何中断。 nginx 的热升级流程也是类似，只不过由于 nginx 工作是多进程，故它会先启动新版本的一组 master/worker 进程； 然后停止老的 worker 进程，让其不处理连接，由新的 worker 进程来处理连接； 升级完毕后，即可退出老的 master 进程，热升级完成。 ","date":"2020-12-28","objectID":"/server-hot-update/:4:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"热更新 热更新目标： 1、正在处理中的连接/服务/请求不能立即中断，需要继续提供服务 2、socket 对用户来说要保持可用，可以接受新的请求 直接沿用上篇的思路，热更新（单进程）流程，其基本流程如下： 1、用新的 bin 文件去替换老的 bin 文件 2、发送信号告知 server 进程（通常是 USR2 信号），进行平滑升级 3、server 进程收到信号后，通过调用 fork/exec 启动新的版本的进程 4、子进程调用接口获取从父进程继承的 socket 文件描述符重新监听 socket 5、老的进程不再接受请求，待正在处理中的请求处理完后，进程自动退出 6、子进程托管给 init 进程 我们可以按照这个思路完成一个简单的可以热更新的 http server ","date":"2020-12-28","objectID":"/server-hot-update/:5:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"简易的 http server 首先，我们需要一个最简单的 http server func main() { fmt.Println(\"Hello World!\") var err error // 注册 http 请求的处理方法 http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"Hello world!\")) }) // 在 8086 端口启动 http 服务，其内部有一个循环 accept 8086 端口 // 每当新的 HTTP 请求过来则开一个协程处理 err = http.ListenAndServe(\"localhost:8086\", nil) if err != nil { log.Println(err) } } ","date":"2020-12-28","objectID":"/server-hot-update/:5:1","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"fork 一个新的进程 在 go 语言里面可以有很多种方法 fork 一个新的进程，但是在这里我更倾向于推荐 exec.Command 接口来启动一个新的进程。因为 Cmd struct 中有一个 ExtraFiles 变量，子进程可以通过它直接继承文件描述符 fd。 func forkProcess() error { var err error files := []*os.File{gListen.File()} //demo only one //.File() path := \"/Users/yousa/work/src/graceful-restart-demo/graceful-restart-demo\" args := []string{ \"-graceful\", } env := append( os.Environ(), \"ENDLESS_CONTINUE=1\", ) env = append(env, fmt.Sprintf(`ENDLESS_SOCKET_ORDER=%s`, \"0,127.0.0.1\")) cmd := exec.Command(path, args...) //cmd := exec.Command(path, \"-graceful\", \"true\") cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr cmd.ExtraFiles = files cmd.Env = env err = cmd.Start() if err != nil { log.Fatalf(\"Restart: Failed to launch, error: %v\", err) return err } return nil } 代码浅析： 在上面的 files 是存储父进程的文件描述符，path 的内容是新的要替换的可执行文件的路径。 重要的一点是，.File() 返回一个 dup(2) 的文件描述符。这个重复的文件描述符不会设置 FD_CLOEXEC 标志，这个文件描述符操作容易出错，容易被在子进程中被错误关闭。 在其他语言（或者 go 里面）里面你可能通过使用命令行将文件描述符传递给子进程，在这里比较推荐使用 ExtraFile 传递 fd。不过 ExtraFiles 在 windows 中不支持。 args 中传递的-graceful 参数是告诉子进程这是优雅热升级的一部分，这样子进程可以通过它知道，自己需要重用套接字而不是重新打开一个新的套接字 ","date":"2020-12-28","objectID":"/server-hot-update/:5:2","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"子进程初始化 func main() { fmt.Println(\"Hello World!\") ... var gracefulChild bool var netListen net.Listener var err error args := os.Args ... if len(args) \u003e 1 \u0026\u0026 args[1] == \"-graceful\" { gracefulChild = true } else { gracefulChild = false } fmt.Println(\"gracefulChild:\", gracefulChild) if gracefulChild { //重用套接字 log.Print(\"main: Listening to existing file descriptor 3.\") f := os.NewFile(3, \"\") netListen, err = net.FileListener(f) } else { log.Print(\"main: Listening on a new file descriptor.\") netListen, err = net.Listen(\"tcp\", gServer.Addr) } if err != nil { log.Fatal(err) return } ... } args 用于解析入参，gracefulChild 表示进程自己是否是子进程（对应到 fork 中的-graceful）（这里更推荐 flag.BoolVar，但是写 demo 的时候使用起来有些问题，故临时使用 args） net.FileListener 重用套接字，ExtraFiles 中传递的套接字，从 idx 3 的位置开始获取。 ","date":"2020-12-28","objectID":"/server-hot-update/:5:3","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"给父进程发送信号停止父进程 func main() { //init ... if gracefulChild { syscall.Kill(syscall.Getppid(), syscall.SIGTERM) log.Println(\"Graceful shutdown parent process.\") } //start http server. ... } 给父进程发送 graceful shutdown 信号 ","date":"2020-12-28","objectID":"/server-hot-update/:5:4","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"优雅停止父进程 等待请求超时或者处理完成退出进程 第一眼给人感觉，不知道该如何下手做热升级。 我们需要去跟踪连接，故想到的是有没有钩子函数来解决连接的 accept 和 close，让人觉得 Golang 标准 http 包没有提供任何钩子来处理 Accept() 和 Close()，这里恰恰是 golang 的 interface 的魅力所在。 interface 基础知识请自行补充 我们需要一个 sync.WaitGroup 来跟踪已经打开的连接，每新 accept 一个连接则让其加一，每当连接断开则减一。定义一个 listener struct 并实现相应的 Accept()、Close()、Addr() 等方法。 type demoListener struct { net.Listener stopped bool stop chan error } func newDemoListener(listen net.Listener) (demoListen *demoListener) { demoListen = \u0026demoListener{ Listener: listen, stop: make(chan error), } return } func (listen *demoListener) Accept() (conn net.Conn, err error) { conn, err = listen.Listener.Accept() if err != nil { return } conn = demoConn{Conn: conn} gWg.Add(1) return } func (listen *demoListener) Close() error { if listen.stopped { return syscall.EINVAL } listen.stopped = true return listen.Listener.Close() //停止接受新的连接 } //get fd func (listen *demoListener) File() *os.File { // returns a dup(2) - FD_CLOEXEC flag *not* set tcpListen := listen.Listener.(*net.TCPListener) fd, _ := tcpListen.File() return fd } demoListener 定义的时候，通过匿名结构体（可以理解为是一种组合），继承了 net.Listener 的结构和方法，下面的 Accept 和 Close 则重载了 net.Listener 的 Accept 和 Close 方法。 Listener 在每个 Accept() 上都增加了一个等待组。 newDemoListener() 是 Listener 的构造函数。 File() 方法是从 Listener 中获取文件描述符 fd 当然，我们需要重载连接 net.Conn 的 Close() 方法，在连接断开时，将 wg 减一 type demoConn struct { net.Conn } func (conn demoConn) Close() error { err := conn.Conn.Close() if err == nil { gWg.Done() } return nil } 最后，有可能客户端已经很长时间不发消息了，但是他不主动断开连接；为了避免这种情况，server 端通常认为这种是连接超时，在一定时间后会将连接关闭，故初始化 http.Server 时比较建议这样： gServer = \u0026http.Server{ Addr: \"0.0.0.0:8086\", ReadTimeout: 60 * time.Second, WriteTimeout: 60 * time.Second, MaxHeaderBytes: 1 \u003c\u003c 16, Handler: demoHandler{}, } 注意：若使用的 go 版本在 1.8 版本以上（包括），http 包已经支持优雅退出，直接调用 Shutdown() 接口即可，更为简单。 关闭 listener 连接和监控信号的部分这里便不再赘述，文末附有源码，有兴趣可以看看。 测试结果： 启动 server，发送 http 请求 YOUSALI-MB0:~ yousa$ curl -i http://localhost:8086 HTTP/1.1 200 OK Date: Mon, 05 Nov 2018 08:11:17 GMT Content-Length: 17 Content-Type: text/plain; charset=utf-8 Hello Tencent! 发送 usr2 信号给 server YOUSALI-MB0:graceful-restart-demo yousa$ ps -ef | grep grace 501 50199 41134 0 4:10 下午 ttys002 0:00.01 ./graceful-restart-demo 501 50252 44808 0 4:11 下午 ttys003 0:00.00 grep grace YOUSALI-MB0:graceful-restart-demo yousa$ kill -USR2 50199 YOUSALI-MB0:graceful-restart-demo yousa$ ps -ef | grep grace 501 50253 1 0 4:11 下午 ttys002 0:00.01 /Users/yousa/work/src/graceful-restart-demo/graceful-restart-demo -graceful 501 51460 44808 0 4:37 下午 ttys003 0:00.00 grep grace ## 终端打印 Hello World! gracefulChild: false 2018/11/05 16:10:16 main: Listening on a new file descriptor. 2018/11/05 16:11:10 50199 Received SIGUSR2. Hello World! gracefulChild: true 2018/11/05 16:11:10 main: Listening to existing file descriptor 3. 2018/11/05 16:11:10 Graceful shutdown parent process. 2018/11/05 16:11:10 50199 Received SIGTERM. 待升级后发送消息 YOUSALI-MB0:~ yousa$ curl -i http://localhost:8086 HTTP/1.1 200 OK Date: Mon, 05 Nov 2018 08:11:44 GMT Content-Length: 14 Content-Type: text/plain; charset=utf-8 Happy 20th birthday! ","date":"2020-12-28","objectID":"/server-hot-update/:5:5","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"遇到的问题 1、翻了下代码，并没有看到父进程如何退出？是怎样的流程？ 先看一下 http ListenAndServe 接口，它会调用 net.Listen 和 serve.Serve 两个函数，net.Listen 是 listen 端口。 Serve 代码如下，它是一个 for 循环，Accept 一个新的连接后会用一个新的协程来处理请求；当 listen 的端口被关闭或者异常后，该 Serve 循环便会跳出 另外，也可以在这里看到，如果让 http server 接入协程池则可以重载 http.Server 的 Serve，在收到新的连接后，从协程池中分配一个协程供新的连接使用。 func (srv *Server) Serve(l net.Listener) error { defer l.Close() var tempDelay time.Duration // how long to sleep on accept failure for { rw, e := l.Accept() if e != nil { if ne, ok := e.(net.Error); ok \u0026\u0026 ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay \u003e max { tempDelay = max } srv.logf(\"http: Accept error: %v; retrying in %v\", e, tempDelay) time.Sleep(tempDelay) continue } return e } tempDelay = 0 c, err := srv.newConn(rw) if err != nil { continue } c.setState(c.rwc, StateNew) // before Serve can return go c.serve() } } 再看一下 shutdownProcess 函数，故在这里关闭 listen socket 后，http Serve 处理请求的主循环便会退出 func shutdownProcess() error { gServer.SetKeepAlivesEnabled(false) gListen.Close() log.Println(\"shutdownProcess success.\") return nil } 将 listen socket 关闭后，main 函数中的 gServer.Serve(gListen) 便会退出，但实际上已有的连接/服务并没有处理完成，需要使用 waitgroup 等待连接处理完成后，进程再退出。 ","date":"2020-12-28","objectID":"/server-hot-update/:5:6","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"github 上的已有开源方案 解决 golang http server 热更新问题，有了基本的思路之后，想到的是去 github 看下有没有稳定的解决方案。找到了如下三个库： fvbock/endless - Zero downtime restarts for golang HTTP and HTTPS servers. (for golang 1.3+) facebookgo/grace - Grace provides a library that makes it easy to build socket based servers that can be gracefully terminated \u0026 restarted (that is, without dropping any connections). jpillora/overseer - Overseer is a package for creating monitorable, gracefully restarting, self-upgrading binaries in Go (golang) 其实除了这些外，还有一些支持热更新的库，但是更新时间过老，在这里就不作讨论了。 当然，非常火爆的框架比如 beego 等，也支持热升级/gracefun shutdown，但是由于嵌入到了 beego 中，故本章中不作讨论，有兴趣的可以自行去看看。 ","date":"2020-12-28","objectID":"/server-hot-update/:6:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"实现浅析 我们使用官方的例子来简单分析其流程并简单比较其异同 1、各个开源库 demo 代码 demo 代码较为冗长，很影响阅读观感，故贴在了最后的附录中 2、对比 操作步骤： 编译 demo 示例，启动示例进程，记录其 pid 修改内容 (Hello Tencent 初始内容，修改为 Happy 20th Birthday！且请求处理均需要 sleep 10-20 秒），重新构建。 发送请求，发送热升级信号，再发送请求，对比两次请求内容 对比进程热升级前后的 pid，是否与之前一致 结果对比 第三方库 第一次请求返回 第二次请求返回 操作前进程 pid 操作后进程 pid facebookgo/grace Hello Tencent Happy 20th Birthday！ 41992 41998 fvbock/endless Hello Tencent Happy 20th Birthday！ 41200 41520 jpillora/overseer Hello Tencent Happy 20th Birthday！ 43424 43424 原理浅析： grace 和 endless 的热升级方法与本文重点讲述的方法一致，基本是 fork 一个子进程，子进程 listen 端口，父进程优雅退出，这里便不再赘述 overseer 的热升级与 grace/endless 有些不同，由于作者很久不更新了（差不多 1-2 年），也找不到比较好的介绍文章，故这里只能简要贴一下其 github 上对 overseer 的原理介绍。由于不是本文核心介绍内容，放在附录中。 overseer 用一个主进程管理平滑重启，子进程处理连接，保持主进程 pid 不变； 优缺点对比： grace 库支持 net tcp 热升级以及 http 热升级，endless 仅支持 http 热升级 grace 库接入第三方 http server 较麻烦（比如 fasthttp、gin 等）；endless 接入则只需要替换 ListenAndServe 即可（endless 继承/重写了 Serve 方法），通用性更好 grace 库功能强大，但是稍微复杂；endless 库更为简洁 由于我的项目使用了 gin 作为 http 框架，故考虑到快速集成，我选择了 endless 该框架 第三方库的对比经验： 主观因素：个人品味，是否要自己造轮子，朋友的推荐也对个人的判断也有很大影响； 客观因素：集成复杂度，内存管理，是否有大量 I/O 访问/耗性能访问，错误处理，工具参考文档等。 集成起来也非常方便，类似于如下： func main() { router := gin.Default() router.GET(\"/\", handler) // [...] endless.ListenAndServe(\":8086\", router) } ","date":"2020-12-28","objectID":"/server-hot-update/:6:1","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"问题拓展 我其实又想了这些问题，也想抛出来与大家一起讨论 1、简单的 http server 很容易升级，若监听了多个端口该如何进行热升级？ 2、若 go server 使用 tls 服务（其他也类似），如何进行升级？ 3、go http server 在容器场景下是否需要平滑热升级？平滑停机是否足够？如果平滑停机足够的话，那么如何结合 docker+k8s 进行热升级？ 个人猜测了一下，这种场景下，后端服务应该会有冗余部署，前端通过负载均衡/elb/tgw 等中间层访问，或者使用 consul 之类的服务注册发现机制，串行重启或者分批次重启，来做到不停服升级服务 ","date":"2020-12-28","objectID":"/server-hot-update/:6:2","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"总结 热更新目标： 1、正在处理中的连接/服务/请求不能立即中断，需要继续提供服务 2、socket 对用户来说要保持可用，可以接受新的请求 直接沿用上篇的思路，热更新（单进程）流程，其基本流程如下： 1、用新的 bin 文件去替换老的 bin 文件 2、发送信号告知 server 进程（通常是 USR2 信号），进行平滑升级 3、server 进程收到信号后，通过调用 fork/exec 启动新的版本的进程 4、子进程调用接口获取从父进程继承的 socket 文件描述符重新监听 socket 5、老的进程不再接受请求，待正在处理中的请求处理完后，进程自动退出 6、子进程托管给 init 进程 ","date":"2020-12-28","objectID":"/server-hot-update/:7:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"参考 https://grisha.org/blog/2014/06/03/graceful-restart-in-golang/ https://blog.csdn.net/u012058778/article/details/78705536 http://gulu-dev.com/post/2014-07-28-tech-evaluation https://golang.org/doc/go1.8#http_shutdown golang1.8 升级日志，支持 gracefulshutdown ","date":"2020-12-28","objectID":"/server-hot-update/:8:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"代码附录 1、facebookgo/grace // Command gracedemo implements a demo server showing how to gracefully // terminate an HTTP server using grace. package main import ( \"flag\" \"fmt\" \"net/http\" \"os\" \"time\" \"github.com/facebookgo/grace/gracehttp\" ) var ( address0 = flag.String(\"a0\", \":48567\", \"Zero address to bind to.\") address1 = flag.String(\"a1\", \":48568\", \"First address to bind to.\") address2 = flag.String(\"a2\", \":48569\", \"Second address to bind to.\") now = time.Now() ) func main() { flag.Parse() gracehttp.Serve( \u0026http.Server{Addr: *address0, Handler: newHandler(\"Zero \")}, \u0026http.Server{Addr: *address1, Handler: newHandler(\"First \")}, \u0026http.Server{Addr: *address2, Handler: newHandler(\"Second\")}, ) } func newHandler(name string) http.Handler { mux := http.NewServeMux() mux.HandleFunc(\"/sleep/\", func(w http.ResponseWriter, r *http.Request) { duration, err := time.ParseDuration(r.FormValue(\"duration\")) if err != nil { http.Error(w, err.Error(), 400) return } time.Sleep(duration) fmt.Fprintf( w, \"%s started at %s slept for %d nanoseconds from pid %d.\\n\", name, now, duration.Nanoseconds(), os.Getpid(), ) }) return mux } 2、fvbock/endless package main import ( \"log\" \"net/http\" \"os\" \"github.com/fvbock/endless\" \"github.com/gorilla/mux\" ) func handler(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"WORLD!\")) } func main() { mux1 := mux.NewRouter() mux1.HandleFunc(\"/hello\", handler). Methods(\"GET\") err := endless.ListenAndServe(\"localhost:4242\", mux1) if err != nil { log.Println(err) } log.Println(\"Server on 4242 stopped\") os.Exit(0) } 3、jpillora/overseer package main import ( \"fmt\" \"net/http\" \"time\" \"github.com/jpillora/overseer\" \"github.com/jpillora/overseer/fetcher\" ) //see example.sh for the use-case // BuildID is compile-time variable var BuildID = \"0\" //convert your 'main()' into a 'prog(state)' //'prog()' is run in a child process func prog(state overseer.State) { fmt.Printf(\"app#%s (%s) listening...\\n\", BuildID, state.ID) http.Handle(\"/\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { d, _ := time.ParseDuration(r.URL.Query().Get(\"d\")) time.Sleep(d) fmt.Fprintf(w, \"app#%s (%s) says hello\\n\", BuildID, state.ID) })) http.Serve(state.Listener, nil) fmt.Printf(\"app#%s (%s) exiting...\\n\", BuildID, state.ID) } //then create another 'main' which runs the upgrades //'main()' is run in the initial process func main() { overseer.Run(overseer.Config{ Program: prog, Address: \":5001\", Fetcher: \u0026fetcher.File{Path: \"my_app_next\"}, Debug: false, //display log of overseer actions }) } 4、overseer overseer uses the main process to check for and install upgrades and a child process to run Program. The main process retrieves the files of the listeners described by Address/es. The child process is provided with these files which is converted into a Listener/s for the Program to consume. All child process pipes are connected back to the main process. All signals received on the main process are forwarded through to the child process. Fetcher runs in a goroutine and checks for updates at preconfigured interval. When Fetcher returns a valid binary stream (io.Reader), the master process saves it to a temporary location, verifies it, replaces the current binary and initiates a graceful restart. The fetcher.HTTP accepts a URL, it polls this URL with HEAD requests and until it detects a change. On change, we GET the URL and stream it back out to overseer. See also fetcher.S3. Once a binary is received, it is run with a simple echo token to confirm it is a overseer binary. Except for scheduled restarts, the active child process exiting will cause the main process to exit with the same code. So, overseer is not a process manager. [外链图片转存失败，源站可能有防盗链机制，建议将图片保存下来直接上传 (img-nJwx0ZVC-1609089892264)(https://camo.githubusercontent.com/45df268c40025baddcafea70a437537c8c67b31c/68747470733a2f2f646f63732e676f6f676c652e636f6d2f64726177696e67732f642f316f31326e6a597952494c79335544733245364a7a794a456c3070735534655059694d5132306a6975564f592f7075623f773d35363626","date":"2020-12-28","objectID":"/server-hot-update/:9:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"参考 http://tengine.taobao.org/nginx_docs/cn/docs/control.html ","date":"2020-12-28","objectID":"/server-hot-update/:10:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"附加技巧 nginx 如何在指定时间内热重启？ envoy 热重启流程跟一般golang进程、nginx进程又有什么异同？ ","date":"2020-12-28","objectID":"/server-hot-update/:11:0","tags":["nginx","golang"],"title":"从 nginx 热更新聊一聊 Golang 中的热更新","uri":"/server-hot-update/"},{"categories":null,"content":"C/C++ 版本 int CNetOperations::GetLocalIp(__be32 *pLocalIp, const char* pIfName) { if (!pLocalIp || !pIfName) { return (-EINVAL); } int iSocket; iSocket = socket(AF_INET, SOCK_DGRAM, 0); if (iSocket \u003c 0) { return (-errno); } struct ifreq stIfr; memset(stIfr.ifr_name, 0x0, sizeof(stIfr.ifr_name)); strcpy(stIfr.ifr_name, pIfName); int iRet; iRet = ioctl(iSocket, SIOCGIFADDR, \u0026stIfr); if (iRet \u003c 0) { close(iSocket); return (-errno); } (*pLocalIp) = ((struct sockaddr_in *)\u0026stIfr.ifr_addr)-\u003esin_addr.s_addr; close(iSocket); return 0; } ","date":"2020-11-25","objectID":"/how-to-get-localip/:1:0","tags":["code"],"title":"获取服务器本机 IP 的不同语言实现","uri":"/how-to-get-localip/"},{"categories":null,"content":"golang 版本 ","date":"2020-11-25","objectID":"/how-to-get-localip/:2:0","tags":["code"],"title":"获取服务器本机 IP 的不同语言实现","uri":"/how-to-get-localip/"},{"categories":null,"content":"shell 版本 最初的想法 进一步改进 localip=`ip route get 1 | awk '{print $NF;exit}'` 局限性 ","date":"2020-11-25","objectID":"/how-to-get-localip/:3:0","tags":["code"],"title":"获取服务器本机 IP 的不同语言实现","uri":"/how-to-get-localip/"},{"categories":null,"content":"lua/Openresty 版本 依赖 luasocket 库的写法 xxx 原理 局限性 使用 ffi 调用的方式实现 xxx 原理 局限性 ","date":"2020-11-25","objectID":"/how-to-get-localip/:4:0","tags":["code"],"title":"获取服务器本机 IP 的不同语言实现","uri":"/how-to-get-localip/"},{"categories":null,"content":"perf 使用教程 ","date":"2020-11-25","objectID":"/perf/:0:0","tags":["profile","perf"],"title":"perf 入门教程（待补充和完善）","uri":"/perf/"},{"categories":null,"content":"perf 简介 Perf 是 Linux kernel 中的系统性能优化工具，perf 基本原理的话是在 CPU 的 PMU register 中 Get/Set performance counters 来获得诸如 instructions executed，cache-missed suffered，branches mispredicted 等信息。 perf 本身的工具有很多，这里主要介绍个人在查询程序性能问题时使用的一些工具 包括 perf list、perf stat、perf record、perf report ","date":"2020-11-25","objectID":"/perf/:1:0","tags":["profile","perf"],"title":"perf 入门教程（待补充和完善）","uri":"/perf/"},{"categories":null,"content":"perf list 使用 perf 之前肯定要知道 perf 能监控哪些性能指标吧？那么就要使用 perf list 进行查看，通常使用的指标是 cpu-clock/task-clock 等，具体要根据需要来判断 $ perf list List of pre-defined events (to be used in -e): cpu-cycles OR cycles [Hardware event] instructions [Hardware event] … cpu-clock [Software event] task-clock [Software event] context-switches OR cs [Software event] … ext4:ext4_allocate_inode [Tracepoint event] kmem:kmalloc [Tracepoint event] module:module_load [Tracepoint event] workqueue:workqueue_execution [Tracepoint event] sched:sched_{wakeup,switch} [Tracepoint event] syscalls:sys_{enter,exit}_epoll_wait [Tracepoint event] … 不同内核版本列出的结果不一样多。.. 不过基本是够用的，但是无论多少，我们可以基本将其分为三类 Hardware Event 是由 PMU 硬件产生的事件，比如 cache 命中，当您需要了解程序对硬件特性的使用情况时，便需要对这些事件进行采样 Software Event 是内核软件产生的事件，比如进程切换，tick 数等 Tracepoint event 是内核中的静态 tracepoint 所触发的事件，这些 tracepoint 用来判断程序运行期间内核的行为细节，比如 slab 分配器的分配次数等 具体监控哪个变量的话，譬如使用后面的 perf report 工具，则加**-e 监控指标**，如 perf report -e cpu-clock ls 监控运行 ls 命令时的 cpu 时钟占用监控 ","date":"2020-11-25","objectID":"/perf/:2:0","tags":["profile","perf"],"title":"perf 入门教程（待补充和完善）","uri":"/perf/"},{"categories":null,"content":"perf stat 刚刚知道了可以监控哪些事件，但是事件这么多，该如何下手呢？ 解决问题的时候有条理才解决的更快，所以面对一个性能问题的时候，最好采用自顶向下的策略。先整体看看该程序运行时各种统计事件的大概，再针对某些方向深入细节。而不要一下子扎进琐碎细节，会一叶障目的。 整体监测代码性能就需要使用 perf stat 这个工具，该工具主要是从全局上监控，可以看到程序导致性能瓶颈主要是什么原因。因为不同的程序导致其性能瓶颈的原因不同，譬如有些程序慢是由于计算量大，而有些程序是由于频繁的 I/O 导致性能瓶颈，他们的优化方式不同。perf stat 通过概括精简的方式提供被调试程序运行的整体情况和汇总数据。 使用方法 perf stats 程序 譬如 perf stat ./gw --gtpu-ip 172.31.24.58 --sgw-s11-ip 172.31.24.250 --zmq-ip 172.31.31.174 --sgi-if eth1 --teid 1 --mysql 172.31.20.157 -cgw 程序运行完之后，然后使用 ctrl+c 来终止程序（若程序自动终止则不用），之后，perf 便会打印出监控事件结果，类似结果如下： Performance counter stats for './gw --gtpu-ip 172.31.24.58 --sgw-s11-ip 172.31.24.250 --zmq-ip 172.31.31.174 --sgi-if eth1 --teid 1 --mysql 172.31.20.157 -cgw': 1773.651816 task-clock (msec) # 0.016 CPUs utilized 79,054 context-switches # 0.045 M/sec 757 cpu-migrations # 0.427 K/sec 16,368 page-faults # 0.009 M/sec \u003cnot supported\u003e cycles \u003cnot supported\u003e stalled-cycles-frontend \u003cnot supported\u003e stalled-cycles-backend \u003cnot supported\u003e instructions \u003cnot supported\u003e branches \u003cnot supported\u003e branch-misses 109.795527410 seconds time elapsed 1773.651816 task-clock 是指程序运行期间占用了 xx 的任务时钟周期，该值高，说明程序的多数时间花费在 CPU 计算上而非 IO 79,054 context-switches 是指程序运行期间发生了 xx 次上下文切换，记录了程序运行过程中发生了多少次进程切换，频繁的进程切换是应该避免的。（有进程进程间频繁切换，或者内核态与用户态频繁切换） 757 cpu-migrations 是指程序运行期间发生了 xx 次 CPU 迁移，即用户程序原本在一个 CPU 上运行，后来迁移到另一个 CPU 16,368 page-faults 是指程序发生了 xx 次页错误 其他可以监控的譬如分支预测、cache 命中等 ","date":"2020-11-25","objectID":"/perf/:3:0","tags":["profile","perf"],"title":"perf 入门教程（待补充和完善）","uri":"/perf/"},{"categories":null,"content":"perf record 前面通过 perf stat 获得了程序性能瓶颈类型，之后，假设你已经知道哪个进程需要优化**（若不知道则需要使用 perf top 进行进一步监控，这里由于个人没有使用过，所以不作介绍）**，那么下一步就是对该进程进行细粒度的分析，分析在长长的程序代码中究竟是哪几段代码、哪几个函数需要修改呢？**这便需要使用 perf record 记录单个函数级别的统计信息，并使用 perf report 来显示统计结果。** 调优应该将注意力集中到百分比高的热点代码片段上，假如一段代码只占用整个程序运行时间的 0.1%，就算将其优化到仅剩一条机器指令，恐怕也只能将整体的程序性能提高 0.1%。 好钢用在刀刃上 仍以之前的 gw 程序为例，假设要监控的指标为 cpu-clock perf record -e cpu-clock -g ./gw --gtpu-ip 172.31.24.58 --sgw-s11-ip 172.31.24.250 --zmq-ip 172.31.31.174 --sgi-if eth1 --teid 1 --mysql 172.31.20.157 -cgw -g 选项是告诉 perf record 额外记录函数的调用关系，因为原本 perf record 记录大都是库函数，直接看库函数，大多数情况下，你的代码肯定没有标准库的性能好对吧？除非是针对产品进行特定优化，所以就需要知道是哪些函数频繁调用这些库函数，通过减少不必要的调用次数来提升性能 -e cpu-clock 指 perf record 监控的指标为 cpu 周期 程序运行完之后，perf record 会生成一个名为 perf.data 的文件（缺省值），如果之前已有，那么之前的 perf.data 文件会变为 perf.data.old 文件 获得这个 perf.data 文件之后，我们其实还不能直接查看，下面就需要 perf report 工具进行查看 ","date":"2020-11-25","objectID":"/perf/:4:0","tags":["profile","perf"],"title":"perf 入门教程（待补充和完善）","uri":"/perf/"},{"categories":null,"content":"perf report 前面通过perf record工具获得了某一进程的指标监控数据 perf.data，下面就需要使用perf report工具查看该文件 使用方法 perf report -i perf-report 生成的文件 譬如 perf report -i perf.data 上面使用perf record获得的数据的结果如下 + 4.93% gw libcurl-gnutls.so.4.3.0 [.] 0x000000000001e1e0 + 4.93% gw [kernel.kallsyms] [k] eventfd_write + 2.96% gw [kernel.kallsyms] [k] ipt_do_table + 2.46% gw [kernel.kallsyms] [k] xen_hypercall_event_channel_op ? 1.97% gw libc-2.19.so [.] _int_malloc + 1.97% gw libc-2.19.so [.] __clock_gettime ? 1.97% gw gw [.] nwGtpv2cHandleInitialReq(NwGtpv2cStack*, unsigned int, MqPackage\u0026) ? 1.97% gw [kernel.kallsyms] [k] pvclock_clocksource_read ? 1.97% gw [kernel.kallsyms] [k] ip_finish_output ? 1.97% gw [kernel.kallsyms] [k] ixgbevf_xmit_frame + 1.48% gw [kernel.kallsyms] [k] kmem_cache_alloc_trace ? 1.48% gw [kernel.kallsyms] [k] sk_run_filter [.] 代表该调用属于用户态，若自己监控的进程为用户态进程，那么这些即主要为用户态的 cpu-clock 占用的数值，[k] 代表属于内核态的调用。 也许有的人会奇怪为什么自己完全是一个用户态的程序为什么还会统计到内核态的指标？一是用户态程序运行时会受到内核态的影响，若内核态对用户态影响较大，统计内核态信息可以了解到是内核中的哪些行为导致对用户态产生影响；二则是有些用户态程序也需要依赖内核的某些操作，譬如 I/O 操作 /+ 4.93% gw libcurl-gnutls.so.4.3.0 [.] 0x000000000001e1e0 ，左边的加号代表 perf 已经记录了该调用关系，按 enter 键可以查看调用关系，不过由于这个是动态库里的函数，基本查看到的都是一些二进制数值：P perf 监控 gw 进程结果记录到很多内核调用，说明 gw 进程在运行过程中，有可能被内核态任务频繁中断，应尽量避免这种情况，对于这个问题我的解决办法是采用绑核，譬如机器有 8 个 CPU，那么我就绑定内核操作、中断等主要在 0-5CPU，GW 由于有两个线程，分别绑定到 6、7CPU 上 ","date":"2020-11-25","objectID":"/perf/:5:0","tags":["profile","perf"],"title":"perf 入门教程（待补充和完善）","uri":"/perf/"},{"categories":null,"content":"实践 这里使用我在实验中程序在某一场景 CPU 占用率飙升的问题作为示例 ","date":"2020-11-25","objectID":"/perf/:6:0","tags":["profile","perf"],"title":"perf 入门教程（待补充和完善）","uri":"/perf/"},{"categories":null,"content":"1.perf stat 整体定位性能瓶颈 CPU 飙升场景与正常场景使用 perf stat 对比差异 执行 perf stat ./gw --gtpu-ip 172.31.24.58 --sgw-s11-ip 172.31.24.250 --zmq-ip 172.31.31.174 --sgi-if eth1 --teid 1 --mysql 172.31.20.157 -cgw CPU 飙升场景 Performance counter stats for './gw --gtpu-ip 172.31.24.58 --sgw-s11-ip 172.31.24.250 --zmq-ip 172.31.31.174 --sgi-if eth1 --teid 1 --mysql 172.31.20.157 -cgw': 1773.651816 task-clock (msec) # 0.016 CPUs utilized 79,054 context-switches # 0.045 M/sec 757 cpu-migrations # 0.427 K/sec 16,368 page-faults # 0.009 M/sec \u003cnot supported\u003e cycles \u003cnot supported\u003e stalled-cycles-frontend \u003cnot supported\u003e stalled-cycles-backend \u003cnot supported\u003e instructions \u003cnot supported\u003e branches \u003cnot supported\u003e branch-misses 109.795527410 seconds time elapsed 正常场景 Performance counter stats for './gw --gtpu-ip 172.31.24.58 --sgw-s11-ip 172.31.24.250 --zmq-ip 172.31.31.174 --sgi-if eth1 --teid 1 --mysql 172.31.20.157 -cgw': 1186.728996 task-clock (msec) # 0.018 CPUs utilized 78,284 context-switches # 0.066 M/sec 69 cpu-migrations # 0.058 K/sec 16,368 page-faults # 0.014 M/sec \u003cnot supported\u003e cycles \u003cnot supported\u003e stalled-cycles-frontend \u003cnot supported\u003e stalled-cycles-backend \u003cnot supported\u003e instructions \u003cnot supported\u003e branches \u003cnot supported\u003e branch-misses 64.456003339 seconds time elapsed 通过对比可以发现： task-clock 异常场景比正常场景占用率高许多，说明程序 CPU 占用率提升 cpu-migrations 异常场景比正常场景占用率高许多，说明进程发生了较频繁的从一个 CPU 迁移到另一个 CPU ","date":"2020-11-25","objectID":"/perf/:6:1","tags":["profile","perf"],"title":"perf 入门教程（待补充和完善）","uri":"/perf/"},{"categories":null,"content":"2.perf record+perf report 单点定位进程本身问题 通过 perf stat 整体上监控进程性能问题之后，使用 perf record 等对进程本身进行监控 执行 perf record -e task-clock -g ./gw --gtpu-ip 172.31.24.58 --sgw-s11-ip 172.31.24.250 --zmq-ip 172.31.31.174 --sgi-if eth1 --teid 1 --mysql 172.31.20.157 -cgw perf report -i perf.data 结果如下 root@ip-172-31-24-250:/home/ubuntu/EPC/gw# + 4.93% gw libcurl-gnutls.so.4.3.0 [.] 0x000000000001e1e0 + 4.93% gw [kernel.kallsyms] [k] eventfd_write + 2.96% gw [kernel.kallsyms] [k] ipt_do_table + 2.46% gw [kernel.kallsyms] [k] xen_hypercall_event_channel_op ? 1.97% gw libc-2.19.so [.] _int_malloc + 1.97% gw libc-2.19.so [.] __clock_gettime ? 1.97% gw gw [.] nwGtpv2cHandleInitialReq(NwGtpv2cStack*, unsigned int, MqPackage\u0026) ? 1.97% gw [kernel.kallsyms] [k] pvclock_clocksource_read ? 1.97% gw [kernel.kallsyms] [k] ip_finish_output ? 1.97% gw [kernel.kallsyms] [k] ixgbevf_xmit_frame + 1.48% gw [kernel.kallsyms] [k] kmem_cache_alloc_trace ? 1.48% gw [kernel.kallsyms] [k] sk_run_filter ? 1.48% gw [kernel.kallsyms] [k] fib_table_lookup ? 1.48% gw [kernel.kallsyms] [k] _raw_spin_unlock_irqrestore ? 0.99% gw libpthread-2.19.so [.] __libc_fcntl + 0.99% gw libc-2.19.so [.] vfprintf ? 0.99% gw libc-2.19.so [.] malloc ? 0.99% gw libc-2.19.so [.] free ? 0.99% gw libc-2.19.so [.] inet_ntop ? 0.99% gw libc-2.19.so [.] inet_pton + 0.99% gw [vdso] [.] 0x0000000000000ca1 ? 0.99% gw [kernel.kallsyms] [k] __do_softirq ? 0.99% gw [kernel.kallsyms] [k] ksize ? 0.99% gw [kernel.kallsyms] [k] kfree + 0.99% gw [kernel.kallsyms] [k] fput ? 0.99% gw [kernel.kallsyms] [k] d_alloc_pseudo ? 0.99% gw [kernel.kallsyms] [k] sys_socket ? 0.99% gw [kernel.kallsyms] [k] datagram_poll ? 0.99% gw [kernel.kallsyms] [k] skb_network_protocol + 0.99% gw [kernel.kallsyms] [k] __dev_queue_xmit libcurl-gnutls.so.4.3.0 它本身功能是一个数据上报，但是占用较高的 CPU，说明调用该库存在问题（代码本身问题），需要对调用该库的代码进行检查 libc-2.19.so [.] _int_malloc 这是常用的 malloc 操作，由于对代码比较熟悉，在这个过程中不应该有这么多次申请内存，说明代码本身有问题，需要对申请动态内存的代码进行检查 __clock_gettime 这个是由于计时需要，需要频繁获取时间，通常是指 gettimeofday() 函数 整个统计显示有很多 task-clock 占用是由于** kernel.kallsyms **导致，同时也验证了对 perf stat 获得的数据的初步判断，即 CPU 飙升也与频繁的 CPU 迁移（内核态中断用户态操作）导致，解决办法是采用 CPU 绑核 perf 工具很好用，要善用这个利器 ","date":"2020-11-25","objectID":"/perf/:6:2","tags":["profile","perf"],"title":"perf 入门教程（待补充和完善）","uri":"/perf/"},{"categories":null,"content":"自我提问 perf 是什么？ perf 能解决什么样的问题？什么样的问题无法解决？为什么？ 如何理解 perf 的探针？在 C++/C/Go/Rust 场景下，这些探针有代表什么含义呢？ perf 是如何统计的？perf 的探测机制是什么？为什么 perf 的探测对性能影响有限？ 使用上，perf 可以衡量哪些指标？针对于什么语言？针对于哪些问题可以评估？可以绘制哪些图？ 后起之秀 bcc/ebpf 与 perf 的取舍？ perf 的哪些机制值得学习？如何使用 perf？能够用 perf 解决什么样的问题？perf 对应指标分别是什么？如何理解这些指标？perf 解决问题的技巧？perf 是如何统计数据的？perf 为什么统计数据可以比较高性能？perf 的局限性有哪些？perf 与后起之秀的 pk？ 一些具体的场景和案例 ","date":"2020-11-25","objectID":"/perf/:7:0","tags":["profile","perf"],"title":"perf 入门教程（待补充和完善）","uri":"/perf/"},{"categories":null,"content":"本文主要分享火焰图使用技巧，介绍 systemtap 的原理机制，如何使用火焰图快速定位性能问题原因，同时加深对 systemtap 的理解。","date":"2020-11-25","objectID":"/flame/","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":" 本文主要分享火焰图使用技巧，介绍 systemtap 的原理机制，如何使用火焰图快速定位性能问题原因，同时加深对 systemtap 的理解。 让我们回想一下，曾经作为编程新手的我们是如何调优程序的？通常是在没有数据的情况下依靠主观臆断来瞎蒙，稍微有些经验的同学则会对差异代码进行二分或者逐段调试。这种定位问题的方式不仅耗时耗力，而且还不具有通用性，当遇到其他类似的性能问题时，需要重复踩坑、填坑，那么如何避免这种情况呢？ 俗语有云：“工欲善其事，必先利其器。”个人认为，程序员定位性能问题也需要一件“利器”。 如同医生给病人看病，需要依靠专业的医学工具（比如 X 光片、听诊器等）进行诊断，最后依据医学工具的检验结果快速精准地定位出病因所在。性能调优工具（比如 perf / gprof 等）之于性能调优就像 X 光之于病人一样，它可以一针见血地指出程序的性能瓶颈。 但是常用的性能调优工具 perf 等，在呈现内容上只能单一地列出调用栈或者非层次化的时间分布，不够直观。这里我推荐大家配合使用火焰图，它将 perf 等工具采集的数据呈现得更为直观。 ","date":"2020-11-25","objectID":"/flame/:0:0","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"初识火焰图 火焰图（Flame Graph）是由 Linux 性能优化大师 Brendan Gregg 发明的，和所有其他的 profiling 方法不同的是，火焰图以一个全局的视野来看待时间分布，它从底部往顶部，列出所有可能导致性能瓶颈的调用栈。 火焰图整个图形看起来就像一个跳动的火焰，这就是它名字的由来。 火焰图有以下特征（这里以 on-cpu 火焰图为例）： 每一列代表一个调用栈，每一个格子代表一个函数； 纵轴展示了栈的深度，按照调用关系从下到上排列，最顶上格子代表采样时，正在占用 cpu 的函数； 横轴的意义是指：火焰图将采集的多个调用栈信息，通过按字母横向排序的方式将众多信息聚合在一起。需要注意的是它并不代表时间； 横轴格子的宽度代表其在采样中出现频率，所以一个格子的宽度越大，说明它是瓶颈原因的可能性就越大； 火焰图格子的颜色是随机的暖色调，方便区分各个调用信息； 其他的采样方式也可以使用火焰图， on-cpu 火焰图横轴是指 cpu 占用时间，off-cpu 火焰图横轴则代表阻塞时间； 采样可以是单线程、多线程、多进程甚至是多 host，进阶用法可以参考附录 进阶阅读； ","date":"2020-11-25","objectID":"/flame/:1:0","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"火焰图类型 常见的火焰图类型有 On-CPU，Off-CPU，还有 Memory，Hot/Cold，Differential 等等。他们分别适合处理什么样的问题呢？ 这里笔者主要使用到的是 On-CPU、Off-CPU 以及 Memory 火焰图，所以这里仅仅对这三种火焰图作比较，也欢迎大家补充和斧正。 ","date":"2020-11-25","objectID":"/flame/:1:1","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"火焰图分析技巧 纵轴代表调用栈的深度（栈桢数），用于表示函数间调用关系：下面的函数是上面函数的父函数； 横轴代表调用频次，一个格子的宽度越大，越说明其可能是瓶颈原因； 不同类型火焰图适合优化的场景不同，比如 on-cpu 火焰图适合分析 cpu 占用高的问题函数，off-cpu 火焰图适合解决阻塞和锁抢占问题； 无意义的事情：横向先后顺序是为了聚合，跟函数间依赖或调用关系无关；火焰图各种颜色是为方便区分，本身不具有特殊含义； 多练习：进行性能优化有意识的使用火焰图的方式进行性能调优（如果时间充裕）； ","date":"2020-11-25","objectID":"/flame/:1:2","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"如何绘制火焰图？ 要生成火焰图，必须要有一个顺手的动态追踪工具，如果操作系统是 Linux 的话，那么通常通常是 perf 或者 systemtap 中的一种。其中 perf 相对更常用，多数 Linux 都包含了 perf 这个工具，可以直接使用；SystemTap 则功能更为强大，监控也更为灵活。网上关于如何使用 perf 绘制火焰图的文章非常多而且丰富，所以本文将以 SystemTap 为例。 SystemTap 是动态追踪工具，它通过探针机制，来采集内核或者应用程序的运行信息，从而可以不用修改内核和应用程序的代码，就获得丰富的信息，帮你分析、定位想要排查的问题。SystemTap 定义了一种类似的 DSL 脚本语言，方便用户根据需要自由扩展。不过，不同于动态追踪的鼻祖 DTrace ，SystemTap 并没有常驻内核的运行时，它需要先把脚本编译为内核模块，然后再插入到内核中执行。这也导致 SystemTap 启动比较缓慢，并且依赖于完整的调试符号表。 使用 SystemTap 绘制火焰图的主要流程如下： 安装 SystemTap 以及 操作系统符号调试表 根据自己所需绘制的火焰图类型以及进程类型选择合适的脚本 生成内核模块 运行 SystemTap 或者运行生成的内核模块统计数据 将统计数据转换成火焰图 本文演示步骤将会基于操作系统 Tlinux 2.2 ( Linux 内核版本 3.10.107) ","date":"2020-11-25","objectID":"/flame/:2:0","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"安装 SystemTap 以及 操作系统符号调试表 使用 yum 工具安装 systemtap: yum install systemtap systemtap-runtime 由于 systemtap 工具依赖于完整的调试符号表，而且生产环境不同机器的内核版本不同（虽然都是 Tlinux 2.2 版本，但是内核版本后面的小版本不一样，可以通过 uname -a 命令查看）所以我们还需要安装 kernel-debuginfo 包、 kernel-devel 包 我这里是安装了这两个依赖包 kernel-devel-3.10.107-1-tlinux2-0046.x86_64 kernel-debuginfo-3.10.107-1-tlinux2-0046.x86_64 ","date":"2020-11-25","objectID":"/flame/:2:1","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"根据自己所需绘制的火焰图类型以及进程类型选择合适的脚本 使用 SystemTap 统计相关数据往往需要自己依照它的语法，编写脚本，具有一定门槛。幸运的是，github 上春哥（agentzh）开源了两组他常用的 SystemTap 脚本：openresty-systemtap-toolkit 和 stapxx，这两个工具集能够覆盖大部分 C 进程、nginx 进程以及 Openresty 进程的性能问题场景。 我们这里需要绘制 off-cpu 火焰图，所以使用 sample-bt-off-cpu 脚本即可 ","date":"2020-11-25","objectID":"/flame/:2:2","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"生成内核模块 现在我们有了统计脚本，也安装好了 systemtap，正常来说就可以使用了，但由于 systemtap 是通过生成内核模块的方式统计相关探针的统计数据，而 tlinux 要求所有运行的内核模块需要先到 tlinux 平台签名才可以运行，所以： 故需要先修改 off-cpu 脚本，让其先生成内核模块；之后对该内核模块作签名；最后使用 systemtap 命令手工运行该脚本，统计监控数据。 Systemtap 执行流程如下： parse：分析脚本语法 elaborate：展开脚本 中定义的探针和连接预定义脚本库，分析内核和内核模块的调试信息 translate：. 将脚本编译成 c 语言内核模块文件放 在$HOME/xxx.c 缓存起来，避免同一脚本多次编译 build：将 c 语言模块文件编译成。ko 的内核模块，也缓存起来。 把模块交给 staprun，staprun 加载内核模块到内核空间，stapio 连接内核模块和用户空间，提供交互 IO 通道，采集数据。 所以我们这里修改下 off-cpu 的 stap 脚本，让其只运行完第四阶段，只生成一个内核模块 // 在 stap 命令后增加 -p4 参数，告诉 systemtap，当前只需要执行到第四阶段 open my $in, \"|stap -p4 --skip-badvars --all-modules -x $pid -d '$exec_path' --ldd $d_so_args $stap_args -\" or die \"Cannot run stap: $!\\n\"; 修改好之后运行脚本，会生成一个内核模块 // -p 8682 是需要监控的进程的进程号 // -t 30 是指会采样 30 秒 ./sample-bt-off-cpu -p 8692 -t 30 生成的内核模块名称形如 stap_xxxxx.ko模块名称 由于读者并不需要关心内核模块签名，故章节略过 ","date":"2020-11-25","objectID":"/flame/:2:3","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"运行内核模块统计数据 内核模块签名完成后，便可以使用 staprun 命令手工运行相关内核模块了 命令： // 注意：签名脚本会将生产的内核模块重命名，需要将名字改回去……（脚本 bug） staprun -x {进程号} {内核模块名} \u003e demo.bt 值得注意的是，监控的进程要有一定负载 systemtap 才可以采集到相关数据，即在采集时，同时需要要有一定请求量（通常是自己构造请求，压测进程） ","date":"2020-11-25","objectID":"/flame/:2:4","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"将统计数据转换成火焰图 获得了统计数据 demo.bt 后，便可以使用火焰图工具绘制火焰图了 下载 FlameGraph，链接：https://github.com/brendangregg/FlameGraph 命令： ./stackcollapse-stap.pl demo.bt \u003e demo.folded ./flamegraph.pl demo.folded \u003e demo.svg 这样便获得了 off-cpu 火焰图： ","date":"2020-11-25","objectID":"/flame/:2:5","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"看图说话 趁热打铁，通过几张火焰图熟悉下如何使用火焰图 图片源于春哥微博或者本人近期绘制的性能火焰图 ","date":"2020-11-25","objectID":"/flame/:3:0","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"on-cpu 火焰图 Apache APISIX QPS 急剧下降问题 Apache APISIX 是一个开源国产的高性能 API 网关，之前在进行选型压测时，发现当 Route 匹配不中场景下， QPS 急剧下降，在其 CPU （四十八核）占用率几乎达到 100%的情况下只有几千 QPS，通过绘制火焰图发现，其主要耗时在一个 table 插入阶段 (lj_cf_table_insert)，分析代码发现是该 table 一直没有释放，每次匹配不中时，路由会向一张用于统计的表中插入一条数据，导致该表越来越大，后续插入耗时过长导致 QPS 下降。 ","date":"2020-11-25","objectID":"/flame/:3:1","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"off-cpu 火焰图 nginx 互斥锁问题 这是一张 nginx 的 off-cpu 火焰图，我们可以很快锁定到 ngx_common_set_cache_fs_size -\u003e ngx_shmtx_lock -\u003e sem_wait 这段逻辑使用到了互斥锁，它让 nginx 进程绝大部分阻塞等待时间花费在获取该锁。 agent 监控上报断点问题 这是一张 agent 的 off-cpu 火焰图，它是一个多线程异步事件模型，主线程处理各个消息，多个线程分别负责配置下发或者监控上报。当前问题出现在监控上报性能差，无法在周期（一分钟）内完成监控数据上报，导致监控断点，通过 off-cpu 火焰图我们可以分析出，该上报线程花费了大量的时间使用 curl_easy_perform 接口收发 http 监控数据消息。 依据火焰图将发送 http 消息的逻辑改为异步非阻塞后，该问题解决。 ","date":"2020-11-25","objectID":"/flame/:3:2","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"附录 ","date":"2020-11-25","objectID":"/flame/:4:0","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"进阶阅读 谷歌搜索演讲：Blazing Performance with Flame Graphs 演讲 ppt：https://www.slideshare.net/brendangregg/blazing-performance-with-flame-graphs 《SystemTap 新手指南》：https://spacewander.gitbooks.io/systemtapbeginnersguide_zh/content/index.html 极客时间《Linux 性能优化实战》–倪朋飞 ","date":"2020-11-25","objectID":"/flame/:4:1","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":null,"content":"FAQ 使用 perf 或者 systemtap 的方式采集数据，会对后台服务有性能影响吗？ 有，但是很小，可以基本忽略不计。 它们使用系统的探针或者使用一些自定义的动态探针进行数据采集，第一对代码无侵入性，它既不需要停止服务，也不需要修改应用程序的代码；第二，它们是以内核模块/内核原生的方式跟踪用户态和内核态的所有事件，并通过一系列优化措施，进行采样统计，对目标服务性能影响极小，大概在 5%左右或者更低的性能损耗。相较于将进程运行在沙箱的 valgrind 工具或静态调试工具 gdb 来说，动态追踪 perf 或者 systemtap 或者 ebpf 的性能损耗基本可以忽略不计。 目标进程重启后，systemtap 是否需要重新生成内核模块？ 不需要。甚至同一个 linux 内核版本下的同一个二进制进程（md5 值一致），在安装 kernel 调试符号表后，便可以在生成采集指标的内核模块，并且可以多次使用。 当 linux 内核版本不一致，符号表有变化，需要重新生成内核模块；当目标进程二进制文件重新编译后，也需要重新生成统计用的 systemtap 内核模块。 如何在容器中绘制火焰图？ 如果是 on-cpu 火焰图可以直接使用perf record命令绘制即可 如果是 off-cpu 之类的火焰图，则需要另外分析 若系统/容器支持 ebpf 可以使用 bcc 工具集，使用如下命令绘制 off-cpu 火焰图 /usr/share/bcc/tools/offcputime -df -p `pgrep -nx mysqld` 30 \u003e out.stacks ","date":"2020-11-25","objectID":"/flame/:4:2","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图","uri":"/flame/"},{"categories":["Env"],"content":"Github Pages 建站教程 ","date":"2020-10-10","objectID":"/how-to-create-blog/","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"十一假期宅家无事，发现自己过去写了很多文章，却没有一个自己的博客，系统得管理自己的文章，所以准备将自己过去以及未来的文章都放到博客，以饷读者。另一方面，经过对 Serverless 博客、TCB 建站、虚拟机建站等一系列建站方式对比后，个人认为基于 Github Pages 最适合搭建个人技术博客，最重要的当然是免费，其次网上教程众多，可以快速建站，第三则是所有的博客直接托管在 github，也更符合个人习惯，最后则是自建个人博客可玩性和可扩展性好。 当然，这个方案并不是完美无缺，缺点也比较明显，比如需要考虑到安全信息泄漏问题（比如可能会泄露公司内的机密信息或者秘钥到 Github，所以需要准备安全扫描方案，这个我们会在另一篇文章谈）；另一方面，读者需要能够翻墙才可以访问 Github Pages；最后，则是没有 CDN 加速，如果访问者众多或者网站图片众多，加载速度很慢。 ","date":"2020-10-10","objectID":"/how-to-create-blog/:0:0","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"为什么要写技术文章？ 其实，个人写文章最初是兴趣使然以及工作需要。众所周知，IT 是一个技术革新很快的行业，新的概念、新的语言、新的框架层出不穷，程序员需要持续学习，我有对每一个新的知识有做笔记的习惯，笔记攒多了便需要回顾总结整理，便形成了一篇篇的文章。 以前笔记的图找不到了，差不多在习惯使用电子笔记之前有十几本笔记，后来我习惯性使用思维导图 processon 等一系列工具记录笔记，比如这张图便是我做的思维导图笔记的冰山一角： 那么，写技术文章有何价值？个人认为写技术文章的价值主要有三方面：个人价值、企业价值和社会价值、企业价值。从个人角度来说，技术写作是树立个人技术影响力，提升自我价值的最快路径，没有之一；从公司角度，坚持长线的写作，对于公司的技术品牌，技术文化，有着巨大的推动作用；从更高的维度来说，技术写作也是提升整个社会技术水平，推动技术不断进步的源动力。 ","date":"2020-10-10","objectID":"/how-to-create-blog/:1:0","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"hugo 初探 ","date":"2020-10-10","objectID":"/how-to-create-blog/:2:0","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"hugo 是什么？ Hugo 是由 Go 语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 hugo 中文官方文档 hugo 英文官方文档 ","date":"2020-10-10","objectID":"/how-to-create-blog/:2:1","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"安装 hugo 在 windows 下，你可以在此处下载 windows 版本下载链接 如果你是 mac 系统，则可以通过如下命令安装（需要先安装 homebrew） brew install hugo ","date":"2020-10-10","objectID":"/how-to-create-blog/:2:2","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"确认 hugo 安装是否成功 通过检查版本号的方式，确认 hugo 安装是否成功 hugo version Hugo Static Site Generator v0.73.0/extended darwin/amd64 BuildDate: unknown # 输出结果 ","date":"2020-10-10","objectID":"/how-to-create-blog/:2:3","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"初始化网站目录 安装好之后，便可以初始化一个 hugo 项目， hugo new site demosite # 命令格式，hugo new site \u003c项目名称\u003e ","date":"2020-10-10","objectID":"/how-to-create-blog/:2:4","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"下载一个 hugo 主题 hugo 主题可以理解为是一种网站样式，你可以在该页面选择自己心仪的 hugo 主题。我当前使用的是 LoveIt 这个主题，集成了很多插件，很好用很方便的一个中文博客模板。 进入该目录，初始化 git 项目，并下载 hugo 主题 cd demosite git init #初始化 git 项目 git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt #下载主题 博客会采用 git 项目方式管理，所以需要初始化 git 项目 采用 submodule 的方式管理主题库 theme，方便及时更新和管理 ","date":"2020-10-10","objectID":"/how-to-create-blog/:2:5","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"配置主题 使用 LoveIt 的标准配置文件模板 cp themes/LoveIt/exampleSite/config.toml . 需要修改一下主题路径 themesDir 配置，将其注释掉 ","date":"2020-10-10","objectID":"/how-to-create-blog/:2:6","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"创建文章 创建一篇空文章 hugo new posts/demo.md 另外，需要将生成文章头部的draft=true修改为draft=false，否则并不会生成草稿页面 ","date":"2020-10-10","objectID":"/how-to-create-blog/:2:7","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"启动 hugo 服务器 启动 hugo 服务器，进入 http://localhost:1313/ 预览页面 hugo server -D 页面预览如下 ","date":"2020-10-10","objectID":"/how-to-create-blog/:2:8","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"构建静态页面 若要将博客托管在 github 上，需要上传静态页面。所以，需要使用 hugo 构建静态页面，构建命令如下： hugo -D ","date":"2020-10-10","objectID":"/how-to-create-blog/:2:9","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"使用 Github Pages 搭建个人博客 ","date":"2020-10-10","objectID":"/how-to-create-blog/:3:0","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"个人博客整体架构 一个静态博客数据有两部分，一部分是静态页面（体积小），另一部分是图片或者大文件（文件体积大），通常来讲一个网站整体结构是静态页面放在服务器上（比如可以使用虚拟机、自己的服务器、github pages 项目），而对于大文件或者图片则通常会使用对象存储服务（比如对象存储或者 github 项目），它们前端使用一个 CDN 进行加速（比如云厂商的 CDN 服务或者 cloudinary），当然，在 HTTPS 已经普及的时代，一个 HTTPS 服务也是必不可少的。 整体架构图如下： 经过综合考量，个人建站选用组件如下： 静态网站服务器：Github Pages 图片上传工具：picgo 图片存储服务：Github 项目 + jsdelivr 加速 域名服务商/域名购买：NameCheap HTTPS/CDN 服务提供商：Cloudfare 腾讯云服务中的 TCB 一键建站也挺好用的。但是因为个人图省钱和喜欢折腾，还是选择自己建站自己选择组件，一方面免费，另一方面可以对网络有更加深刻的理解。 ","date":"2020-10-10","objectID":"/how-to-create-blog/:3:1","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"Github Pages 是什么？ GitHub Pages 是一项静态站点托管服务，它直接从 GitHub 上的仓库获取 index.html、HTML、CSS 和 JavaScript 文件，也可以通过构建过程运行文件，然后发布网站。 GitHub Pages 可以识别指定分支根目录或者/docs 目录下的静态站点，具体可以在个人站点的 setting 中配置。 Github Pages 建站有两种类型： 个人/组织站点，其域名格式形如https://\u003cUSERNAME|ORGANIZATION\u003e.github.io/ 项目站点，其域名格式形如https://\u003cUSERNAME|ORGANIZATION\u003e.github.io/\u003cPROJECT\u003e/ 你需要看清楚你的 Github Pages 建站类型，不同的建站类型的建站方法也不同，具体可以参考 官方手册 这里我们以个人站点（User Pages）为例 ","date":"2020-10-10","objectID":"/how-to-create-blog/:3:2","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"创建 Github Pages 项目 创建一个新的 github 项目，项目名称需要是\u003cusername.github.io\u003e格式，如下图样例 ","date":"2020-10-10","objectID":"/how-to-create-blog/:3:3","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"配置 pages 项目 点击进入 setting，搜索 github pages 关键字，找到相关配置：当前 github 默认分支已经是 main 分支，需要调整下；配置好之后即可通过用户名。github.io最初的 github 页面。 ","date":"2020-10-10","objectID":"/how-to-create-blog/:3:4","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"hugo 生成静态页面 生成静态页面之前需要修改 config.toml 文件中的 baseURL 配置，将其修改为个人站点，比如我的就是 miss-you.github.io 前面我们知道hugo -D可以生成静态页面，但该命令会默认将静态页面生成到 public 目录下，而 Github Pages 仅支持根目录/或者/docs 目录，所以我们需要将静态页面生成到 docs 目录下 hugo -d docs ","date":"2020-10-10","objectID":"/how-to-create-blog/:3:5","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"上传 github pages 项目 静态页面生成完成后，便可以将整个静态页面以及本项目其他文件上传到 github 项目中。先使用git remote命令添加远端仓库，将文件提交（git add+git commit），最后推送到 Github Pages 项目中 git remote add origin git@github.com:Miss-you/miss-you.github.io.git # 将本地 git 项目与 github 项目相关联 git fetch origin # 拉取 github 项目 git checkout main #切换到主分支 main git add . git commit -m \"init github pages\" git push origin 当然，这里也可以采用git clone \u003cYOUR-PROJECT-URL\u003e \u0026\u0026 cd \u003cYOUR-PROJECT\u003e拉取项目、上传文件（git add/commit/push) 的方式，上传 github 项目，这里不作过多演示 ","date":"2020-10-10","objectID":"/how-to-create-blog/:3:6","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"发布脚本 虽然我们已经打通了基于 Github Pages 搭建个人博客的流程，但每次博客有修改都需要执行多条命令才能将博客发布，重复劳动且浪费时间，而程序员的天性是追求效率，应当用自动化（脚本）解决重复的工作。 如下是一个常用脚本，会自动构建静态页面，然后提交构建出来的 docs 静态页面目录，将其推送到对应 Github Pages 项目中 #!/bin/sh # If a command fails then the deploy stops set -e printf \"\\033[0;32mDeploying updates to GitHub...\\033[0m\\n\" # Build the project. hugo -d docs # if using a theme, replace with `hugo -t \u003cYOURTHEME\u003e` # Add changes to git. git add docs # Commit changes. msg=\"rebuilding site $(date)\" if [ -n \"$*\" ]; then msg=\"$*\" fi git commit -m \"$msg\" # Push source and build repos. git push origin main ","date":"2020-10-10","objectID":"/how-to-create-blog/:3:7","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"FAQ ","date":"2020-10-10","objectID":"/how-to-create-blog/:4:0","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"常见操作 TODO 文章插入图片 图片上传问题 图片存储问题 TODO 修改模板 TODO 创建友链 TODO 创建联系方式 TODO ","date":"2020-10-10","objectID":"/how-to-create-blog/:4:1","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"常见问题 Github Pages 项目报错：The submodule registered for ./themes/xxx could not be cloned. 原因是 Github Pages 项目，若要使用 submodule 应用第三方主题，需要使用 https 的地址而不是 git 地址 [TOC] 符号不生效 toc 是 markdown 的一种进阶语法，用于自动生成目录，但是 hugo 并没有支持该语法。目录建议采用主题自带的目录功能，比如本文示例中的 LoveIt 主题。 使用 loveit 或者切换到 loveit 主题入门教程： LoveIt 入门教程 找不到主题，Error: module “LoveIt” not found 原因是由于 LoveIt 示例主题中的 config.toml 文件，其主题路径为”../..\"，该目录下并不会有 LoveIt 主题，将其注释掉即可，或者修改 LoveIt 主题所在的相对路径 github 搜索不到 LoveIt 主题 LoveIt 英文小写是 loveit，不是 lovelt，因为不注意的话 I 和 l 难以区分，容易混淆 jsdelivr latest图片找不到问题 https://cdn.jsdelivr.net/gh/Miss-you/img/how-to-create-blog/20201020132241.png https://cdn.jsdelivr.net/gh/Miss-you/img@1.0/how-to-create-blog/20201020132241.png 必须要带版本号才可以找得到 为什么latest用不了？ github的bug，他们的latest默认会去找master分支的，而不是main分支的图片…… ","date":"2020-10-10","objectID":"/how-to-create-blog/:4:2","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["Env"],"content":"参考链接 hugo 中文官方文档 hugo 英文官方文档 hugo 主题站 github pages 官方手册 hugo loveit 主题使用教程 cloudfare 配置教程 picgo 官方教程 ","date":"2020-10-10","objectID":"/how-to-create-blog/:5:0","tags":["blog","github pages"],"title":"使用 Github Pages 和 Hugo 搭建个人博客教程","uri":"/how-to-create-blog/"},{"categories":["GoLang"],"content":"本文主要介绍如何使用 go 语言 database/sql 库从数据库中读取 null 值的问题，以及如何向数据库中插入 null 值。本文在这里使用的是 sql.NullString, sql.NullInt64, sql.NullFloat64 等结构体，为了方便书写，它们的泛指我会使用 sql.Null 来表示. ","date":"2020-10-08","objectID":"/go-mysql-null/","tags":["mysql","golang"],"title":"Go 语言：解决数据库中 null 值的问题","uri":"/go-mysql-null/"},{"categories":["GoLang"],"content":" 本文主要介绍如何使用 go 语言 database/sql 库从数据库中读取 null 值的问题，以及如何向数据库中插入 null 值。本文在这里使用的是 sql.NullString, sql.NullInt64, sql.NullFloat64 等结构体，为了方便书写，它们的泛指我会使用 sql.Null 来表示 ","date":"2020-10-08","objectID":"/go-mysql-null/:0:0","tags":["mysql","golang"],"title":"Go 语言：解决数据库中 null 值的问题","uri":"/go-mysql-null/"},{"categories":["GoLang"],"content":"要点 从数据库读取可能为 null 值得值时，可以选择使用 sql.NULL 来读取；或者使用 IFNULL、COALESCE 等命令让数据库查询值返回不为\"“或者 NULL 若需要往数据库中插入 null 值，则依然可以使用 sql.NULL 存储所需的值，然后进行插入 NULL 值 直接使用 sql.NULL 类型容易出现 valid 遗漏设置等问题，普通 int、string 与其转换时，请写几个简单的 get、set 函数 本 demo 使用的数据库表以及数据如下 mysql\u003e desc person; +------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +------------+--------------+------+-----+---------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | first_name | varchar(100) | NO | | NULL | | | last_name | varchar(40) | YES | | NULL | | | age | int(11) | YES | | NULL | | +------------+--------------+------+-----+---------+----------------+ mysql\u003e select * from person; +----+------------+-----------+------+ | id | first_name | last_name | age | +----+------------+-----------+------+ | 1 | yousa | NULL | NULL | +----+------------+-----------+------+ mysql\u003e show create table person; +--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Table | Create Table | +--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | person | CREATE TABLE `person` ( `id` int(11) NOT NULL AUTO_INCREMENT, `first_name` varchar(100) NOT NULL, `last_name` varchar(40) DEFAULT NULL, `age` int(11) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 | +--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) ","date":"2020-10-08","objectID":"/go-mysql-null/:1:0","tags":["mysql","golang"],"title":"Go 语言：解决数据库中 null 值的问题","uri":"/go-mysql-null/"},{"categories":["GoLang"],"content":"从数据库中读取 NULL 值 如果不作处理直接从数据库中读取 NULL 值到 string/int，会发生如下错误错误 Scan NULL 值到 string 的报错 sql: Scan error on column index 1: unsupported Scan, storing driver.Value type \u003cnil\u003e into type *string Scan NULL 值到 int 的报错 sql: Scan error on column index 1: converting driver.Value type \u003cnil\u003e (\"\u003cnil\u003e\") to a int: invalid syntax 使用如下的 struct 来读取数据库内容 type Person struct { firstName string lastName string age int } //由于只有一行，直接使用 QueryRow row := db.QueryRow(\"SELECT first_name, last_name FROM person WHERE first_name='yousa'\") err = row.Scan(\u0026hello.firstName, \u0026hello.lastName) if err != nil { fmt.Println(err) } fmt.Println(hello) row1 := db.QueryRow(\"SELECT first_name, age FROM person WHERE first_name='yousa'\") err = row1.Scan(\u0026hello.firstName, \u0026hello.age) if err != nil { fmt.Println(err) } fmt.Println(hello) 运行代码，可以通过日志看出来，错误来自 Scan 将 NULL 值赋值给 int 或者 string 时，报错；解决这个问题可以使用 sql 原生结构体 sql.Null 来解决 ","date":"2020-10-08","objectID":"/go-mysql-null/:2:0","tags":["mysql","golang"],"title":"Go 语言：解决数据库中 null 值的问题","uri":"/go-mysql-null/"},{"categories":["GoLang"],"content":"使用 sqlNull sql.Null 在 sql 库中声明如下，在读取时，（比如读取的值存储到 NullInt64），假如发现存储的值是 NULL，则会将 NullInt64 的 valid 设置为 false，然后不会将值存储到 Int64 中，Int64 值默认为 0，如果是 NullString 则 String 值时 nil；如果是正常值，则会将 Valid 赋值为 true，将值存储到 Int64 中。 type NullInt64 struct { Int64 int64 Valid bool // Valid is true if Int64 is not NULL } func (n *NullInt64) Scan(value interface{}) error func (n NullInt64) Value() (driver.Value, error) type NullString struct { String string Valid bool // Valid is true if String is not NULL } func (ns *NullString) Scan(value interface{}) error func (ns NullString) Value() (driver.Value, error) 代码修改为如下： type Person struct { firstName string lastNullName sql.NullString nullAge sql.NullInt64 } rowNull := db.QueryRow(\"SELECT first_name, last_name FROM person WHERE first_name='yousa'\") err = rowNull.Scan(\u0026hello.firstName, \u0026hello.lastNullName) if err != nil { fmt.Println(err) } fmt.Println(hello) rowNull1 := db.QueryRow(\"SELECT first_name, age FROM person WHERE first_name='yousa'\") err = rowNull1.Scan(\u0026hello.firstName, \u0026hello.nullAge) if err != nil { fmt.Println(err) } fmt.Println(hello) 输出结果 {yousa 0 { false} {0 false}} ","date":"2020-10-08","objectID":"/go-mysql-null/:2:1","tags":["mysql","golang"],"title":"Go 语言：解决数据库中 null 值的问题","uri":"/go-mysql-null/"},{"categories":["GoLang"],"content":"使用 IFNULL 或者 COALESCE coalesce() 解释：返回参数中的第一个非空表达式（从左向右依次类推） IFNULL(expr1,expr2): 如果 expr1 不是 NULL，IFNULL() 返回 expr1，否则它返回 expr2。IFNULL() 返回一个数字或字符串值，取决于它被使用的上下文环境。 查询语句使用一个默认值来替换 NULL 即可 SELECT first_name, COALESCE(age, 0) FROM person;// SELECT first_name, IFNULL(age, 0) FROM person;// ","date":"2020-10-08","objectID":"/go-mysql-null/:2:2","tags":["mysql","golang"],"title":"Go 语言：解决数据库中 null 值的问题","uri":"/go-mysql-null/"},{"categories":["GoLang"],"content":"往数据库中插入 NULL 值 前面我们对 SELECT 语句使用了 sql.Null 类型，同理，INSERT、UPDATE 语句也可以通过使用这种类型来插入 nil 值 代码如下： hello := Person { firstName: \"\", lastName: \"\", age: 0, lastNullName: sql.NullString{String:\"\", Valid:false}, nullAge: sql.NullInt64{Int64:0, Valid:false}} _, err = db.Exec( \"INSERT INTO person (first_name, last_name) VALUES (?, ?)\", \"yousa1\", hello.lastName) if err != nil { fmt.Println(err) } _, err = db.Exec( \"INSERT INTO person (first_name, last_name) VALUES (?, ?)\", \"yousa2\", hello.lastNullName) if err != nil { fmt.Println(err) } //数据库插入结果 mysql\u003e select * from person; +----+------------+-----------+------+ | id | first_name | last_name | age | +----+------------+-----------+------+ | 1 | yousa | NULL | NULL | | 2 | yousa1 | | NULL | | 3 | yousa2 | NULL | NULL | +----+------------+-----------+------+ 解释下 db.Exec 操作 hello.lastNullName 的过程： 首先它会调用 hello.lastNullName 的 Value 方法，获取到 driver.Value，然后检验 Valid 值是 true 还是 false，如果是 false 则会返回一个 nil 值（nil 值传给 sql driver 会被认为是 NULL 值），如果是 true 则会将 hello.lastNullName.String 的值传过去。 PS: 为了保证你所插入的值能如你所期望是 NULL 值，一定记得要将 sql.Null 中 Valid 值置为 false 使用 NULL 还是有很多危害的，再回顾下数据库中使用 NULL 值的危害 ","date":"2020-10-08","objectID":"/go-mysql-null/:3:0","tags":["mysql","golang"],"title":"Go 语言：解决数据库中 null 值的问题","uri":"/go-mysql-null/"},{"categories":["GoLang"],"content":"为什么不建议使用 NULL 所有使用 NULL 值的情况，都可以通过一个有意义的值的表示，这样有利于代码的可读性和可维护性，并能从约束上增强业务数据的规范性。 NULL 值在 timestamp 类型下容易出问题，特别是没有启用参数 explicit_defaults_for_timestamp NOT IN、!= 等负向条件查询在有 NULL 值的情况下返回永远为空结果，查询容易出错 Null 列需要更多的存储空间：需要一个额外字节作为判断是否为 NULL 的标志位 NULL 值到非 NULL 的更新无法做到原地更新，更容易发生索引分裂，从而影响性能。 PS：但把 NULL 列改为 NOT NULL 带来的性能提示很小，除非确定它带来了问题，否则不要把它当成优先的优化措施，最重要的是使用的列的类型的适当性。 当然有些情况是不得不使用 NULL 值进行存储，或者在查询时由于 left/right join 等导致 NULL 值，但总体来说，能少用就少用。 ","date":"2020-10-08","objectID":"/go-mysql-null/:3:1","tags":["mysql","golang"],"title":"Go 语言：解决数据库中 null 值的问题","uri":"/go-mysql-null/"},{"categories":["GoLang"],"content":"helper func（提升效率/减少错误） 如果使用 sql.NULL 的话，由于其有两个字段，如果直接手动赋值的话还是很容易遗漏，所以还是需要简单的转换函数，这里给了两个简单的 helper fuc，分别是将 int64 转换成 NullInt64 和将 string 转换成 NullString //ToNullString invalidates a sql.NullString if empty, validates if not empty func ToNullString(s string) sql.NullString { return sql.NullString{String : s, Valid : s != \"\"} } //ToNullInt64 validates a sql.NullInt64 if incoming string evaluates to an integer, invalidates if it does not func ToNullInt64(s string) sql.NullInt64 { i, err := strconv.Atoi(s) return sql.NullInt64{Int64 : int64(i), Valid : err == nil} } ","date":"2020-10-08","objectID":"/go-mysql-null/:4:0","tags":["mysql","golang"],"title":"Go 语言：解决数据库中 null 值的问题","uri":"/go-mysql-null/"},{"categories":["GoLang"],"content":"参考博客 https://github.com/go-sql-driver/mysql/issues/34 https://github.com/guregu/null https://gocn.io/question/243 https://godoc.org/database/sql http://url.cn/5cFTz4W 一千个不用 Null 的理由 ","date":"2020-10-08","objectID":"/go-mysql-null/:5:0","tags":["mysql","golang"],"title":"Go 语言：解决数据库中 null 值的问题","uri":"/go-mysql-null/"}]