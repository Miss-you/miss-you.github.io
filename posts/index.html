<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | yousa Blog</title><meta name=keywords content><meta name=description content="Posts - yousa Blog"><meta name=author content="Miss-you"><link rel=canonical href=https://miss-you.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://miss-you.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://miss-you.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://miss-you.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://miss-you.github.io/apple-touch-icon.png><link rel=mask-icon href=https://miss-you.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://miss-you.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://miss-you.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://miss-you.github.io/posts/"><meta property="og:site_name" content="yousa Blog"><meta property="og:title" content="Posts"><meta property="og:description" content="为往圣继绝学，为万世开太平"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content="为往圣继绝学，为万世开太平"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://miss-you.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://miss-you.github.io/ accesskey=h title="yousa Blog (Alt + H)">yousa Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://miss-you.github.io/zh/ title=中文 aria-label=中文>Zh</a></li></ul></div></div><ul id=menu><li><a href=https://miss-you.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://miss-you.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://miss-you.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://github.com/Miss-you title=GitHub><span>GitHub</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://miss-you.github.io/>Home</a></div><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Claude Code 还是 Codex？贵但强 vs 便宜但稳</h2></header><div class=entry-content><p>纠结 Claude Code 还是 Codex？一个贵 4 倍但 SWE-bench 高 3%，一个便宜但社区说"更稳定"。这里有最短路径：同一仓库、同一任务的端到端实测——从 UI 克隆到推荐管线，看清每一分钱花在哪。
摘要 同样预算写更多代码 → Codex 更完整不敷衍 → Codex，更倾向完成整个 PR 并补测试 数据分析与快速原型 → Codex，更便宜，开发循环更稳定 代码质量 → Codex，代码质量和规范性更好 前端 UI 还原度 → Claude Code，UI 保真度更高 大规模重构 → Claude Code，更擅长大规模架构调整 复杂任务与系统操作 → Claude Code，SWE-bench 77.2，OSWorld 61.4 首字响应速度 → Claude Code，Vertex TTFT ≈1.67s 超长上下文支持 → Claude Code，多云部署可达 1M 上下文 成本控制与调优 → Codex，可调推理深度，灵活控制速度和费用 端到端项目成本 → Codex，约 $2.50 vs Claude 约 $10.26 表现稳定性 → Codex，运行稳定，调试循环更可靠 文档写作 → Claude Code，文档生成质量更高 图表生成（XML/PlantUML） → Claude Code，结构化图表生成更擅长 端到端开发成本对比 Composio 在同一仓库、同一 MCP 环境下做了实测对比，汇总了不同场景的 Token 与成本差异：
...</p></div><footer class=entry-footer><span title='2025-10-16 13:34:27 +0800 +0800'>October 16, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;679 words&nbsp;·&nbsp;Miss-you</footer><a class=entry-link aria-label="post link to Claude Code 还是 Codex？贵但强 vs 便宜但稳" href=https://miss-you.github.io/posts/20251016-claudecode-vs-codex/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>为什么所有产品最后都要长出社交？</h2></header><div class=entry-content><p>为什么想聊这个 最近在听极客公园关于 Sora/Cameo 的对谈，听到 Lovart 创始人陈冕说的这句话「最大的 ToC 应用就是社交」。
这让我想起来，过去阿里一直想做社交——不论是支付宝、淘宝、闲鱼，都曾经尝试过很多次社交功能。
但现在，我不想讨论这句话对不对，只是想搞清楚：陈冕为什么这么想？
我最开始的疑问是：这句话是不是过时了？毕竟 2025 年大家的时间都在短视频、游戏、长视频，谁还在"社交"?
但查了一圈历史，我发现这个观点从 2013 年就开始有人说，而且说的人越来越多。
我查到的历史 Kik 创始人 Ted Livingston 在 Fast Company 采访中直白地说：“I think everyone is realizing that messaging is the killer app in mobile."（我觉得大家都在意识到，移动端的杀手级应用是消息）。后来很多文章都引用成"移动端最大/最强的 C 端应用就是消息/社交”。
当然 201x 世代，最绕不过的自然是微信。我印象里，说起张小龙做产品，大家都会说：“移动互联网的本质是社交”。
这在产品圈就是说：“做 C 端要么做社交本身，要么让产品自带社交分发”"‘社交 + X’比’X + 社交’更容易起量"——这让我想起来王者荣耀、和平精英，都在做营地。
现在回过头来看，这个说法在 2013–2016 年是对的；但到 2025 年，情况有点变了——社交还在，但已经不是唯一抢夺你我时间的东西了。
现在我会这么说：消息/社交是互联网时代的水和电，短视频/游戏/长视频/图文/短剧/小说是让你留下来的，电商和广告就是为了赚钱的。
这个解释完整吗？我刚才分的三层，说的是现在，但没解释"为什么"——为什么所有产品最后都要长出社交？
我换了个角度想：
换个角度 我想了想自己最常用的那几个 App——Instagram、TikTok、小红书——它们的共同点：都靠关注、点赞、评论、转发这些人和人的交流来运转。我猜这不是巧合。无论是工具、游戏还是内容平台，做到后面好像都要加社交功能。可能比起新功能或新算法，我们更在意"有人在"?
比如王者荣耀、火影忍者手游，游戏 AI 的衡量指标不是有多强，而是对局留存、有多像人。
我觉得「陈冕」说"最大的 To C 应用是社交"，是因为他看懂了用户为什么要用产品。用户需求像个金字塔：最下面的工具是帮你提高效率，中间的内容是让你爽，而最上面的社交，是让你觉得自己重要，被看见。
【待补充】这里还缺一块：网络效应（你朋友都在用你就不想走）、转移成本（换个 App 你的好友、聊天记录、关注、粉丝都没了）、数据护城河。.. 我还没想清楚它们和"让你觉得自己重要"之间到底是什么关系。
...</p></div><footer class=entry-footer><span title='2025-10-10 13:47:40 +0800 +0800'>October 10, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;77 words&nbsp;·&nbsp;Miss-you</footer><a class=entry-link aria-label="post link to 为什么所有产品最后都要长出社交？" href=https://miss-you.github.io/posts/20251010-product-im/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>AI经济学术语速查手册</h2></header><div class=entry-content><p>整理了一批常用且"AI+经济学/计量+业务实践"里高频出现的术语,便于自己日常查询使用
主要有四种:
核心AI与经济概念 (Core AI & Economic Concepts):最宏观、最基本的术语。 商业与财务 (Business & Finance):企业运营和财务绩效相关的术语。 AI技术与实现 (AI Technology & Implementation):更具体的技术和工程术语。 研究方法与统计 (Research Methods & Statistics):经济学论文中用于因果推断的计量方法。 1. 核心AI与经济概念 (Core AI & Economic Concepts) GenAI (Generative AI): 生成式人工智能 解释:能够创造新内容(如文本、图像、代码)的AI系统。这是当前AI浪潮的核心。 LLM (Large Language Model): 大语言模型 解释:GenAI的一种,特指基于海量文本数据训练的、能理解和生成人类语言的模型,如GPT-4。 Agentic AI / Agentic Web: 智能体AI / 智能体网络 解释:能够设定目标、记忆、学习并自主执行复杂任务的下一代AI系统及其构成的生态。 AGI (Artificial General Intelligence): 通用人工智能 解释:拥有与人类同等或更高智慧,能解决任何智力任务的理论上的AI。是AI发展的远期目标。 GPT (General Purpose Technology): 通用目的技术 解释:指像蒸汽机、电力、互联网一样,能够对整个经济产生深远、广泛影响的基础性技术。AI被普遍视为一种新的GPT。 TFP (Total Factor Productivity): 全要素生产率 解释:衡量生产效率的宏观经济指标,指不能由资本和劳动等要素投入解释的产出增长部分,通常归因于技术进步。 CES/Cobb-Douglas (Constant Elasticity of Substitution / Cobb-Douglas Production Function): CES/科布-道格拉斯生产函数 解释:经济学中描述生产要素(如资本与劳动)如何组合产出的函数形式。CES函数允许不同的替代弹性(σ),而科布-道格拉斯是其特例(σ=1)。在AI经济研究中,用于建模技术、人力资本和AI之间的替代或互补关系,分析自动化对要素需求的影响。 σ (Elasticity of Substitution): 替代弹性 解释:衡量生产要素之间可替代程度的参数。σ>1表示要素易于替代(如AI可替代劳动),σ&lt;1表示互补性强(AI需配合人类技能)。在AI经济学中,替代弹性决定了自动化技术对就业和工资的影响方向:高替代弹性意味着AI更可能替代工人,低替代弹性则促进协同增效。 SBTC/RBTC (Skill-Biased Technological Change / Routine-Biased Technological Change): 技能偏向/常规任务偏向技术变革 解释:SBTC指技术进步提高了对高技能劳动的需求,扩大技能溢价和工资不平等(1980-2000年代主导叙事)。RBTC进一步细化,指技术主要替代常规性任务(无论高低技能),导致中等技能岗位空心化(job polarization)。GenAI时代的研究关注其是否延续RBTC模式,或转向认知任务偏向(CBTC)。 Complementarity/Substitution (Complementarity/Substitution): 互补性/替代性 解释:描述技术与劳动之间的两种基本关系。互补性指技术提升劳动生产率(如AI辅助工具增强人类能力),替代性指技术直接取代人类完成任务(如自动化流水线)。GenAI同时展现两种特性:在创意、决策等领域互补,在数据处理、内容生成等领域替代,具体取决于任务特征和实施方式。 Network Effects (Network Effects): 网络效应 解释:产品或服务的价值随用户数量增加而提升的现象,也称需求侧规模经济。在AI平台经济中,更多用户生成更多数据,改进算法质量,吸引更多用户,形成正反馈循环(如社交媒体、在线市场)。网络效应是AI巨头形成市场支配地位的关键机制,也引发数据垄断和竞争政策关注。 Two-Sided Market (Two-Sided Market): 双边市场 解释:平台连接两类或多类相互依赖的用户群体(如司机-乘客、开发者-用户),并通过差异化定价协调供需的市场结构。AI平台(如应用商店、云服务市场)典型表现为双边市场,平台需平衡不同边的参与激励,常采用一边补贴(如免费开发者工具)另一边收费(如用户订阅)的策略。 Switching Costs (Switching Costs): 切换成本 解释:用户从一个产品/服务转向竞争对手时产生的成本,包括经济成本(迁移费用)、学习成本(适应新系统)和心理成本(失去积累数据)。在AI生态中,高切换成本(如专有数据格式、定制化模型、API依赖)形成用户锁定效应,降低市场竞争强度,是平台维持市场力量的重要工具。 Learning Curve (Learning Curve / Experience Curve): 学习曲线/经验曲线 解释:累计生产量增加导致单位成本下降的规律,源于生产经验积累、工艺优化和规模效应。在AI产业中,模型训练成本随数据和算力投入累积而下降,先发企业通过学习曲线效应建立成本优势。经验曲线是解释AI巨头竞争壁垒(如GPU采购规模、模型迭代速度)的重要框架。 O*NET (Occupational Information Network): 职业信息网络 解释:美国劳工部维护的职业任务与技能数据库,详细记录每个职业的工作活动、技能要求、工作背景等标准化信息。AI经济学研究中,ONET是构建"任务暴露度"指标的核心数据源:研究者将AI能力与ONET任务描述匹配,量化不同职业受AI影响的程度(如Felten、Eloundou等的暴露度指标)。 SOC/NAICS (Standard Occupational Classification / North American Industry Classification System): 标准职业分类/北美行业分类系统 解释:SOC是美国政府用于职业统计的标准分类体系(如Software Developers属15-1252),NAICS是行业分类体系(如软件出版业属511210)。AI经济研究依赖这些分类系统关联不同数据源(如劳动力统计、企业调查、O*NET任务数据),分析AI在职业-行业层面的影响差异和传导机制。 PIAAC (Programme for the International Assessment of Adult Competencies): 国际成人能力评估项目 解释:OECD组织的大规模国际调查,评估成人在读写、数理和问题解决等领域的实际技能水平(非学历),涵盖多国样本。在AI与技能研究中,PIAAC数据用于衡量实际认知能力分布、匹配任务需求与技能供给、分析技能错配(skill mismatch)问题,补充基于教育年限的人力资本测量。 Scaling Laws (Scaling Laws): 标度律/缩放定律 解释:描述AI模型性能(如损失函数、准确率)与模型规模(参数量)、训练数据量、计算资源(FLOPs)之间幂律关系的经验规律。OpenAI等机构研究表明,性能提升主要受最稀缺资源约束,且呈现可预测的规模回报。Scaling laws是理解AI能力边界、预测技术进步路径、评估经济可行性(如算力成本与性能收益权衡)的关键工具。 2. 商业与财务 (Business & Finance) P&amp;L (Profit and Loss): 损益表 解释:展示公司在一定时期内收入、成本、费用和利润的财务报表。 EBIT (Earnings Before Interest and Taxes): 息税前利润 解释:衡量企业核心运营盈利能力的指标,排除了利息和税收这两个非运营因素的影响。 ROI (Return on Investment): 投资回报率 解释:衡量投资效益的财务比率,计算公式为 (投资收益 / 投资成本) * 100%。 KPI (Key Performance Indicator): 关键绩效指标 解释:用于量化和衡量业务目标达成度的具体指标,例如网站的"日活跃用户数"或销售的"月度转化率"。 SMBs (Small and Medium-sized Businesses): 中小型企业 解释:通常指员工人数和年收入在特定规模以下的企业,是讨论技术普及和经济影响时的重要分析对象。 BPO (Business Process Outsourcing): 业务流程外包 解释:企业将客户服务、人力资源等非核心业务流程交由第三方公司处理的商业模式。AI正在深刻改变这一行业。 SaaS (Software as a Service): 软件即服务 解释:一种通过互联网订阅使用的软件模式,用户无需本地安装。多数AI工具都采用此模式。 CRM (Customer Relationship Management): 客户关系管理 解释:用于管理公司与现有及潜在客户互动的系统或软件(如Salesforce)。AI正被广泛集成进CRM以提升销售和客服效率。 SLA (Service Level Agreement): 服务级别协议 解释:服务提供商(如云服务、BPO公司)对其服务质量、可用性、响应时间等做出的量化承诺。 CIO / COO: 首席信息官 / 首席运营官 解释:公司高层管理者,CIO负责信息技术战略,COO负责日常运营。他们在推动AI落地中扮演关键角色。 Prosumers (Producer + Consumer): 生产型消费者 解释:既消费产品,又深度参与产品创造、改进或推广的用户。在AI领域,指那些能熟练使用AI工具并创造价值的早期采用者。 ESG (Environmental, Social, and Governance): 环境、社会和治理 解释:评估企业可持续性和社会影响的一套标准。有时也指代提供此类评级的公司。 TCO (Total Cost of Ownership): 全生命周期成本 解释:衡量IT系统或产品从采购、部署到运维、退役的全周期总成本,综合计算资本支出(CapEx)与运营支出(OpEx),帮助企业进行更全面的成本效益分析和采购决策。 CAC/LTV (Customer Acquisition Cost/Lifetime Value): 获客成本/用户终身价值 解释:CAC指获取单个新客户所需的平均营销和销售成本;LTV指单个客户在整个生命周期内为企业带来的总收益。LTV/CAC比值是衡量商业模式健康度的关键指标,通常该比值应大于3。 ARR/MRR (Annual/Monthly Recurring Revenue): 年度/月度经常性收入 解释:SaaS和订阅制企业的核心财务指标,ARR是年度可预期的重复性收入,MRR是月度重复性收入。这些指标帮助企业预测现金流、评估业务增长稳定性,是投资者评估订阅制企业价值的重要依据。 ARPU (Average Revenue Per User): 每用户平均收入 解释:特定时期内总收入除以活跃用户数,是衡量用户变现能力的关键指标。ARPU的提升可通过增加用户付费率、提高定价或促进用户升级到高价值套餐来实现,常用于SaaS、电信和互联网行业。 Churn (Churn Rate): 流失率 解释:特定时期内停止使用产品或取消订阅的客户比例,是订阅制和ToB业务的健康度核心指标。包括客户流失率(Customer Churn)和收入流失率(Revenue Churn),低流失率意味着更高的客户留存和可预测收入。 Unit Economics: 单位经济模型 解释:通过分析单个客户或单次交易的收入与成本,评估商业模式在微观层面的盈利性。核心指标包括单客户获取成本、单客户收益、边际贡献等,是判断业务是否可规模化扩张的基础。 TAM/SAM/SOM (Total/Serviceable/Obtainable Market): 总市场/可服务市场/可获取市场 解释:市场规模的三层分析框架:TAM是理论上的总市场规模;SAM是产品实际能服务的细分市场;SOM是短期内实际可获取的市场份额。这一框架帮助企业制定现实的市场策略和增长目标。 PMF (Product-Market Fit): 产品-市场匹配 解释:产品满足强烈市场需求的状态,是创业公司的关键里程碑。达成PMF的标志包括:用户自发推荐、高留存率、强烈的产品需求。Marc Andreessen认为这是创业成功的首要条件。 On-Prem (On-Premises): 本地化部署 解释:软件或系统部署在客户自有的服务器和基础设施上,而非云端。与SaaS模式相对,On-Prem提供更高的数据控制权和安全性,但需要客户自行承担硬件、运维和升级成本,常见于对数据主权有严格要求的企业和行业。 PaaS (Platform as a Service): 平台即服务 解释:云计算服务模型之一,提供包括操作系统、中间件、数据库、开发工具在内的完整应用开发和部署平台。开发者无需管理底层基础设施,专注于应用程序开发,典型代表包括Heroku、Google App Engine。 IaaS (Infrastructure as a Service): 基础设施即服务 解释:云计算的基础层服务模型,提供虚拟化的计算资源(服务器、存储、网络),用户可按需租用并自行配置操作系统和应用。相比传统IT采购,IaaS提供更高的灵活性和成本效益,代表厂商包括AWS EC2、Azure、阿里云。 SLO (Service Level Objectives): 服务等级目标 解释:服务可靠性的量化目标,定义系统在特定时间段内应达到的性能指标(如可用性99.9%、响应时间&lt;200ms)。SLO是SLA(服务等级协议)的基础,帮助团队在可靠性与开发速度之间找到平衡,是SRE文化的核心实践。 3. AI技术与实现 (AI Technology & Implementation) RAG (Retrieval-Augmented Generation): 检索增强生成 解释:一种让LLM在生成回答前,先从外部知识库(如公司内部文档)检索相关信息的技术,以提高回答的准确性和时效性。 Fine-tuning: 微调 解释:在通用预训练模型的基础上,使用特定领域的数据进行二次训练,使其更适应特定任务(如法律合同分析、医疗诊断问答)。 HITL (Human-in-the-loop): 人机协同 / 人在回路 解释:一种AI系统设计模式,在关键决策点(如医疗诊断、内容审核)保留人工审核、确认或干预的环节,以确保安全和质量。 UI / UX (User Interface / User Experience): 用户界面 / 用户体验 解释:UI指用户与软件交互的视觉界面;UX指用户在使用产品过程中的整体感受。好的UI/UX对AI产品的成功至关重要。 API (Application Programming Interface): 应用程序编程接口 解释:允许不同软件程序相互通信和交换数据的"插座"。企业通过API将AI功能(如OpenAI的API)集成到自己的应用中。 NANDA (Networked Agents And Decentralized Architecture): 网络化智能体与去中心化架构 解释:由MIT提出的一个支持不同AI智能体之间互操作和协作的基础设施框架。 MCP / A2A (Model Context Protocol / Agent-to-Agent): 模型上下文协议 / 智能体到智能体协议 解释:与NANDA相关的技术协议,旨在为AI智能体之间的交流和数据交换建立标准。 SFT (Supervised Fine-Tuning): 监督微调 解释:在预训练大模型的基础上,使用带标注的任务数据进行进一步训练,是模型对齐的第一步。通过监督学习让模型学会遵循指令、回答问题等特定任务,是从基础模型到实用模型的关键环节。 RLHF/RLAIF (Reinforcement Learning from Human/AI Feedback): 基于人类/AI反馈的强化学习 解释:通过强化学习让模型学习人类偏好的对齐技术。RLHF使用人类标注员的偏好反馈,RLAIF则使用AI系统的反馈,两者都通过奖励模型引导模型生成更符合人类价值观和期望的输出,是ChatGPT等产品的核心技术。 DPO (Direct Preference Optimization): 直接偏好优化 解释:一种无需强化学习即可进行偏好对齐的优化方法。相比RLHF,DPO直接从偏好数据中学习,省去了训练奖励模型和复杂的RL训练流程,实现更简单、训练更稳定,成本更低。 LoRA (Low-Rank Adaptation): 低秩适配 解释:一种参数高效的微调技术,通过在模型层中插入低秩矩阵,只训练少量新增参数(通常&lt;1%)即可适配下游任务。大幅降低微调的计算和存储成本,使得在消费级硬件上微调大模型成为可能。 Token: 词元 解释:LLM处理文本的基本单位,通常一个token对应一个词、词的一部分或标点符号(中文约1.5-2字/token)。是API计费、上下文长度限制、成本估算的基础度量单位。 Context Window: 上下文窗口 解释:模型在一次推理中能够读取和处理的最大token数量限制。例如32K、128K上下文窗口,决定了模型能"记住"多长的对话历史或文档内容,是衡量模型能力的重要指标。 Hallucination: 幻觉 解释:LLM生成看似合理但实际虚假或无根据内容的现象。模型可能编造事实、引用不存在的文献、虚构数据等,是当前LLM应用中需要重点防范的风险,需通过RAG、Grounding等技术缓解。 Inference: 推理 解释:模型部署后实际调用生成结果的过程,对应训练(Training)概念。推理性能(延迟、吞吐)和成本是生产环境的核心关注点,涉及模型压缩、硬件加速、批处理等优化技术。 PPL (Perplexity): 困惑度 解释:衡量语言模型预测质量的常用指标,数值越低表示模型对文本的预测越准确。在技术层面,困惑度是模型在测试数据上交叉熵的指数,常用于评估预训练和微调效果。 Pass@k/EM (Pass@k/Exact Match): 通过率@k/精确匹配 解释:代码生成和问答任务的评测指标。Pass@k指生成k个候选答案中至少有一个通过测试用例的比例;EM指生成答案与标准答案完全一致的比例,是评估模型准确性的严格标准。 Embedding: 向量嵌入 解释:将文本、图像等数据转换为固定长度的数值向量表示,使得语义相似的内容在向量空间中距离接近。是语义检索、相似度匹配、RAG系统的基础技术,通过专门的Embedding模型生成。 Vector DB/ANN (Vector Database/Approximate Nearest Neighbor): 向量数据库/近似最近邻 解释:专门用于存储和检索高维向量的数据库系统及其核心算法。ANN算法通过牺牲少量精度换取检索速度的大幅提升,使得在百万、亿级向量中毫秒级找到相似向量成为可能,是RAG系统的基础设施。 Cosine Sim. (Cosine Similarity): 余弦相似度 解释:衡量两个向量方向相似性的度量方法,取值范围-1到1,值越接近1表示越相似。在向量检索中,常用余弦相似度评估文本语义相似性,不受向量长度影响,只关注方向。 HNSW/FAISS (Hierarchical Navigable Small World/Facebook AI Similarity Search): HNSW图/FAISS库 解释:两种主流的ANN索引实现技术。HNSW是基于图的多层导航结构,查询速度快;FAISS是Meta开源的向量检索库,支持多种索引算法和GPU加速,广泛应用于生产环境的向量检索系统。 Grounding: 事实锚定 解释:将模型生成内容与可靠外部来源(如权威文档、数据库、搜索结果)关联的技术,确保输出有据可查。通过引用来源、展示证据链等方式提高答案可信度,是减少幻觉、增强可解释性的重要手段。 Tool Use/Function Calling: 工具调用/函数调用 解释:让LLM能够调用外部工具、API或执行函数的能力。模型可以识别何时需要使用工具、生成正确的调用参数,并整合返回结果,使LLM从纯文本生成扩展到完成实际任务(如查询数据库、调用计算器、操作系统等)。 CoT (Chain-of-Thought): 思维链 解释:一种提示技术,引导模型在给出最终答案前,先生成中间推理步骤。通过"让我们一步步思考"等提示,显著提升模型在数学、逻辑等复杂推理任务上的表现,是学术界和工程实践中广泛应用的Prompt Engineering方法。 PII (Personally Identifiable Information): 可识别个人信息 解释:能够直接或间接识别特定个人身份的信息,如姓名、身份证号、手机号、邮箱等。在AI应用中需严格保护PII,遵守GDPR、个人信息保护法等法规,通过脱敏、加密、访问控制等手段确保数据合规。 SDK (Software Development Kit): 软件开发工具包 解释:为开发者提供的一套集成工具、库、文档和示例代码的软件包,简化应用开发流程。AI厂商通常提供SDK封装API调用,处理认证、重试、流式传输等底层细节,让开发者专注业务逻辑。 ETL/ELT (Extract-Transform-Load/Extract-Load-Transform): 抽取-转换-加载/抽取-加载-转换 解释:数据管道的两种架构模式。ETL先转换再加载,适合传统数仓;ELT先加载原始数据再转换,利用现代数仓的计算能力,在AI数据准备中常用于构建训练数据、知识库等场景。 4. 研究方法与统计 (Research Methods & Statistics) DiD (Difference-in-Differences): 双重差分法 解释:一种经典的准实验方法,通过比较一个受政策影响的"处理组"和一个未受影响的"参照组"在政策前后的变化差异,来估计政策的因果效应。 Event Study: 事件研究法 解释:常被视为DiD的动态版本,通过观察某个事件(如AI发布、政策实施)发生前后,目标变量(如股价、生产率)的时间序列变化来评估事件影响。 IV (Instrumental Variables): 工具变量法 解释:当怀疑自变量(X)和因变量(Y)之间存在内生性问题(如反向因果、遗漏变量)时,引入一个"工具变量"(Z),Z只通过X影响Y,而不直接影响Y,从而分离出X对Y的纯粹因果效应。 RDD (Regression Discontinuity Design): 回归断点设计 解释:一种利用规则或阈值(如分数线、年龄限制)来估计因果效应的方法。它比较阈值两侧非常接近的个体,认为他们的差异主要是由该规则造成的。 OLS (Ordinary Least Squares): 普通最小二乘法 解释:最基础和常用的线性回归技术,用于估计变量间线性关系的系数。 Fixed Effects (FE): 固定效应 解释:在面板数据分析中,用于控制那些不随时间变化的、难以观测的个体异质性(如公司文化、地区特征)的一种统计方法。 Natural Experiment: 自然实验 解释:指现实世界中发生的、其影响类似于随机实验的事件(如政策突变、自然灾害),为研究者提供了识别因果关系的机会。 Exclusion Restriction: 排除性限制 解释:工具变量法成立的核心假设,即工具变量除了通过影响内生自变量外,不能有任何其他途径影响因变量。 RCT (Randomized Controlled Trial): 随机对照试验 解释:因果推断的黄金标准方法,通过随机分配受试者到处理组和对照组,确保两组在统计上可比较,从而消除选择偏差,准确识别因果效应。广泛应用于医学、政策评估和产品实验。 PSM (Propensity Score Matching): 倾向得分匹配 解释:一种准实验方法,通过估计个体接受处理的概率(倾向得分),将处理组和对照组中倾向得分相似的个体进行匹配,从而模拟随机化实验,减少选择偏差,用于观测数据的因果推断。 IPW (Inverse Probability Weighting): 逆概率加权 解释:一种通过加权调整样本分布来纠正选择偏差的方法。对每个观测赋予权重(接受处理概率的倒数),使加权后的样本分布接近随机化实验的分布,常与倾向得分结合使用进行因果推断。 TWFE (Two-Way Fixed Effects): 双向固定效应 解释:面板数据分析中的常用回归模型,同时控制个体固定效应和时间固定效应,是双重差分法(DiD)的标准实现方式。能够控制不随时间变化的个体特征和影响所有个体的时间趋势。 Staggered Adoption: 交错采用 解释:政策或干预措施在不同时间点分批次实施的情境,不同个体或地区在不同时期接受处理。这种设计下的双重差分分析需要特别注意处理时间异质性和动态效应,传统TWFE方法可能产生偏误。 ATT/ATE/ATC (Average Treatment effect on the Treated/Effect/on the Controls): 处理组/总体/对照组平均效应 解释:因果推断中三种不同的平均处理效应定义。ATT衡量实际接受处理者的平均效应,ATE衡量总体的平均效应,ATC衡量未接受处理者假设接受处理的平均效应。不同估计量适用于不同的政策问题。 LATE (Local Average Treatment Effect): 局部平均处理效应 解释:工具变量方法估计的因果效应,特指工具变量影响下"合规者"(因工具变量改变而改变处理状态的子群体)的平均处理效应。LATE通常小于总体效应,其外推性取决于合规者的代表性。 ITT/TOT/CACE (Intention-To-Treat/Treatment-on-the-Treated/Complier Average Causal Effect): 意向治疗/实际接受处理/合规者平均因果效应 解释:处理不完全合规情境下的三种效应估计。ITT基于最初分配估计效应(保留随机化),TOT估计实际接受处理者的效应,CACE等同于LATE。ITT提供保守但稳健的下界估计。 SUTVA (Stable Unit Treatment Value Assumption): 稳定单元处理值假设 解释:因果推断的核心假设之一,要求个体的潜在结果不受其他个体处理状态的影响(无溢出效应),且处理只有一种形式(无隐藏变异)。违反SUTVA会导致因果效应估计偏误,需要考虑网络效应或干扰。 Parallel Trends: 平行趋势假设 解释:双重差分法的核心识别假设,要求在没有政策干预的反事实情境下,处理组和对照组的结果变量趋势应当平行。通常通过事前趋势检验(pre-trend test)和事件研究图来验证该假设的合理性。 DAG (Directed Acyclic Graph): 有向无环图 解释:因果推断中用于表示变量间因果关系的图形工具,节点代表变量,有向边代表因果关系,“无环"确保无循环因果。DAG帮助研究者识别混淆变量、中介变量和对撞变量,指导控制变量的选择。 Backdoor/Frontdoor (Backdoor/Frontdoor Criteria): 后门/前门条件 解释:基于DAG的因果识别准则。后门准则要求控制变量集合阻断所有从处理到结果的"后门路径”(非因果关联路径),前门准则通过中介变量识别因果效应。这两个准则为控制混淆提供了形式化规则。 Weak IV: 弱工具变量 解释:工具变量与内生解释变量相关性较弱的情况,通常用第一阶段回归的F统计量诊断(经验阈值约为10)。弱工具变量会导致估计量偏误、置信区间失效和推断不稳健,需要使用专门的弱工具变量稳健推断方法。 Overidentification Test: 过度识别检验 解释:当工具变量数量多于内生变量时,可以检验工具变量的有效性假设(外生性)。常用的检验包括Sargan检验和Hansen J检验。拒绝原假设表明至少部分工具变量可能不满足外生性条件。 Synthetic Control: 合成控制法 解释:一种准实验方法,用于单个或少数处理单元的政策评估。通过对照组单元的加权组合构造一个"合成对照组",使其在干预前的特征和趋势与处理组尽可能匹配,用合成对照组的干预后结果作为反事实基准估计政策效应。 DML (Double/Debiased Machine Learning): 双重/去偏机器学习 解释:结合机器学习和因果推断的方法,在高维协变量情境下估计因果效应。通过样本分割和交叉拟合,使用机器学习预测干扰变量,同时保证目标因果参数估计的渐近正态性和有效推断,避免正则化偏差。 HTE (Heterogeneous Treatment Effects): 异质性处理效应 解释:不同子群体或个体对同一处理的效应存在差异。识别和估计HTE对于精准政策制定和个性化决策至关重要。常用方法包括子组分析、交互项回归、因果森林和元学习器等机器学习方法。 Clustered SEs (Cluster-Robust SEs): 聚类稳健标准误 解释:当数据存在聚类结构(如学生嵌套于学校、个体重复观测)且组内观测相关时,需要使用聚类稳健标准误进行推断。该方法允许组内任意相关性,但要求聚类数量足够大(通常建议至少30个聚类)。 Newey–West (Newey–West): NW稳健标准误 解释:一种异方差和自相关一致性(HAC)标准误估计方法,用于时间序列数据中存在自相关和异方差的情况。通过选择适当的滞后阶数(带宽),对协方差矩阵进行加权调整,使推断在违反经典假设时仍然有效。 Bootstrap: 自助法 解释:一种基于重抽样的统计推断方法,通过从原始样本中有放回地重复抽样,生成大量"自助样本",从而估计统计量的分布和不确定性。适用于难以得到解析解的复杂估计量,无需依赖渐近分布假设。 Multiple Testing/FDR (False Discovery Rate): 多重检验/错误发现率 解释:当同时进行多个假设检验时,需要调整显著性水平以控制假阳性率膨胀。FDR控制被拒绝原假设中错误拒绝的期望比例,相比传统的族错误率(FWER)控制方法(如Bonferroni校正)更具检验功效。 Bandwidth (RDD): 带宽选择 解释:断点回归设计中的关键调参,决定使用断点附近多大范围内的观测进行局部估计。带宽越小偏差越小但方差越大,带宽越大则相反。常用数据驱动的方法(如IK、CCT)进行最优带宽选择,平衡偏差-方差权衡。 McCrary Test: McCrary密度检验 解释:断点回归设计的有效性检验,检查分配变量(running variable)在断点处是否存在密度跳跃。如果个体可以精确操纵分配变量跨越断点,密度会出现不连续,违反断点回归的随机化假设,导致估计偏误。 A/B Test: A/B测试 解释:在线产品和服务中最常用的随机对照实验方法,通过随机将用户分配到不同版本(A版本和B版本),比较关键指标(如转化率、留存率)的差异,快速评估产品改进或策略调整的因果效应。 MDE (Minimum Detectable Effect): 最小可检出效应 解释:在给定样本量、显著性水平和检验功效下,实验能够可靠检测到的最小效应值。MDE是样本量规划的核心指标,MDE越小需要的样本量越大。在实验设计阶段评估MDE是否满足业务需求至关重要。 Power (Statistical Power): 检验功效 解释:当原假设为假时正确拒绝原假设的概率,记为1-β(β为第二类错误概率)。高功效意味着实验有足够能力发现真实存在的效应。功效分析用于实验设计阶段确定所需样本量,或事后评估未显著结果的可信度。 CTR/CR (Click-Through Rate/Conversion Rate): 点击率/转化率 解释:在线产品和数字营销中的核心业务指标。CTR衡量用户点击率(点击数/曝光数),CR衡量转化率(转化数/访问数)。这些比率型指标是A/B测试的常见目标变量,需注意比率估计的统计性质(如Delta方法)。 Uplift Modeling: 提升模型 解释:一类直接建模处理增量效应的机器学习方法,预测个体接受处理相对于不接受处理的结果差异(个体处理效应)。常用于精准营销和个性化推荐,识别对干预最敏感的用户,优化资源配置和投放策略。 Guardrail Metrics: 护栏指标 解释:在线实验中用于确保产品稳定性、用户体验和生态健康的监控指标。虽然不是实验的主要优化目标,但必须在可接受范围内(如页面加载时间、错误率、用户投诉)。护栏指标异常会触发实验暂停或回滚。 p50/p95/p99: 分位延迟 解释:用于描述系统性能和用户体验的分位数指标,分别表示50%、95%、99%的请求延迟低于该值。相比平均值,分位数对极端值不敏感,能更好地刻画用户实际体验。p95和p99常用于服务等级目标(SLO)设定。 Canary: 金丝雀发布 解释:一种渐进式发布策略,先将新版本部署到小比例流量(如5%),密切监控关键指标和护栏指标,确认无异常后再逐步扩大流量。这种方式能够在早期发现问题并快速回滚,降低发布风险,是工程实践中的风险控制手段。 MLE (Maximum Likelihood Estimation): 极大似然估计 解释:一种参数估计的基本方法,通过最大化观测数据在参数模型下的似然函数来估计参数值。MLE具有良好的大样本性质(一致性、渐近正态性、渐近有效性),是统计推断和计量经济学中最常用的估计方法之一。 Logit/Probit: 二项响应模型 解释:用于二元因变量(0/1)的回归模型。Logit模型假设误差项服从逻辑分布,Probit模型假设服从正态分布。两者通常给出相似结果,Logit模型的系数解释为对数几率比,计算更简便,在实证研究中更为常用。 RE (Random Effects): 随机效应 解释:面板数据模型的一种设定,假设个体特定效应与解释变量不相关,将个体效应视为随机误差的一部分。相比固定效应,随机效应模型更有效率且能估计时间不变变量的系数,但需要更强的外生性假设。Hausman检验用于选择固定或随机效应。 Heteroskedasticity: 异方差 解释:误差项方差随解释变量变化而变化,违反了经典线性回归的同方差假设。异方差会导致OLS标准误估计不一致,使推断失效(虽然系数估计仍然无偏)。常用稳健标准误(White标准误)或加权最小二乘法(WLS)处理异方差。 Normalization/Standardization: 归一化/标准化 解释:特征预处理的常用方法。归一化通常指将数据缩放到[0,1]区间(如Min-Max缩放),标准化指将数据转换为均值为0、标准差为1(Z-score标准化)。这些方法消除量纲影响,改善优化算法收敛性,在机器学习和因果推断中广泛应用。 Winsorize: 温莎化 解释:一种处理极端值的稳健方法,将分布两端超过特定分位数(如1%和99%)的值替换为该分位数的值,而不是直接删除。温莎化保留了样本量,减少极端值对估计的影响,在金融和经济数据分析中特别常用。 Z-score: Z分数 解释:标准化后的数据值,表示原始值距离均值有多少个标准差。Z-score = (X - μ) / σ。Z分数用于跨变量比较、异常值检测(通常|Z|>3视为异常)和标准化处理。在正态分布假设下,Z分数有明确的概率解释。 GLS (Generalized Least Squares): 广义最小二乘 解释:当误差项存在异方差或自相关时,OLS不再是最有效的估计量。GLS通过对观测值进行加权变换,使变换后的误差满足经典假设,从而获得更有效的估计。GLS需要已知误差的协方差结构,实践中常用可行GLS(FGLS)。</p></div><footer class=entry-footer><span title='2025-10-06 17:40:39 +0800 +0800'>October 6, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;736 words&nbsp;·&nbsp;Miss-you</footer><a class=entry-link aria-label="post link to AI经济学术语速查手册" href=https://miss-you.github.io/posts/20251006-ai-economy-keyword-list/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://raw.githubusercontent.com/Miss-you/img/master/painting-tutorials20251009-genai-gap-overview.png alt="GenAI 鸿沟：95% vs 5%的分界线"></figure><header class=entry-header><h2 class=entry-hint-parent>GenAI 工具选购和决策指南</h2></header><div class=entry-content><p>MIT 追踪 300+ 项目揭示：95% GenAI 项目失败的根源与 5% 成功的关键。</p></div><footer class=entry-footer><span title='2025-10-03 17:58:36 +0800 +0800'>October 3, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;730 words&nbsp;·&nbsp;yousa</footer><a class=entry-link aria-label="post link to GenAI 工具选购和决策指南" href=https://miss-you.github.io/posts/20251003-how-to-jump-genai-gap/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>OpenAI研究揭秘：7亿用户如何使用ChatGPT</h2></header><div class=entry-content><p>OpenAI研究揭秘：7亿用户如何使用ChatGPT 2025 年 9 月 15 日，美国国家经济研究局（NBER）发布了一份题为《人们如何使用 ChatGPT》的工作论文。这项研究由 OpenAI 的经济研究团队与哈佛大学经济学家 David Deming 联合完成。通过对 150 万次对话进行隐私保护下的大规模分析，该研究首次全面揭示了全球 7 亿用户是如何使用 ChatGPT 的。
论文要点 主要观点 ChatGPT 的增长是前所未有的：自 2022 年 11 月发布以来，ChatGPT 经历了史无前例的全球性快速增长。到 2025 年 7 月，其周活跃用户（WAU）已超过 7 亿，约占全球成年人口的 10%。用户每日发送的消息量超过 25 亿条。
使用场景以非工作为主，且增长更快：尽管工作相关的使用在稳定增长，但与工作无关的个人用途增长速度更快。非工作用途的消息占比从 2024 年 6 月的 53%增长到了 2025 年 6 月的 73%。
核心功能是决策支持和内容生成：用户主要将 ChatGPT 用于三大目的：“实用指导”、“信息查询"和"写作”，这三者合计占所有对话的近 80%（具体为 77%）。尤其在工作场景中，“写作"是最核心的用途，占所有工作相关消息的 40%（截至 2025 年 6 月）。 用户意图从"执行"转向"提问”：用户的使用模式正在变化。寻求信息、建议以辅助决策的"提问"类互动（占比 49%），其增长速度已超过了让 AI 直接完成任务的"执行"类互动（占比 40%）。同时，用户对"提问"类互动的满意度更高。
用户群体日益多元化：早期的用户以男性为主（约占 80%），但到 2025 年 6 月，拥有典型女性名字的活跃用户比例已略微超过男性，性别差距基本消除。用户群体呈现年轻化趋势，18-25 岁的用户发送了约 46%的消息。此外，在低收入和中等收入国家的增长尤为迅速。
...</p></div><footer class=entry-footer><span title='2025-09-18 00:53:37 +0800 +0800'>September 18, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;141 words&nbsp;·&nbsp;Miss-you</footer><a class=entry-link aria-label="post link to OpenAI研究揭秘：7亿用户如何使用ChatGPT" href=https://miss-you.github.io/posts/20250918-openai-how-people-use-chatgpt/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://raw.githubusercontent.com/Miss-you/img/master/painting-tutorials/021757768438838215a9313f45ebd1c7cc8e15534cbabccad8e59_0.jpeg alt=仓鼠轮中的现代人></figure><header class=entry-header><h2 class=entry-hint-parent>我那套混乱的排序算法：从忙碌焦虑到注意力投资</h2></header><div class=entry-content><p>我那套混乱的排序算法 我忙碌却焦虑的根源，是内心那套将“紧急性”等同于“重要性”，将“新奇感”等同于“价值”的排序算法。
我最近发现一个现象：我的日程表越满，一种深层的焦虑感就越强。无论是在工作日还是在业余时间，我似乎总在忙碌，却感觉在原地踏步。
今天，我意识到，问题的根源并不在于时间管理技巧，而在于我内心深处那套混乱不堪的排序算法。
一个算法，两种 Bug 在工作中，这个算法的 bug 表现为：将“紧急性”等同于“重要性”。
一个临时的会议、一封需要马上回复的邮件，它们就像操作系统里的最高优先级中断，不断抢占我的 CPU 时间。我疲于应对这些信号，却忘了真正驱动长期价值的，是那些需要深度思考、不会大声嚷嚷的“重要不紧急”的任务。我以为在解决问题，其实只是在响应请求。
到了业余时间，这个 bug 换了一种形式：将“新奇感”等同于“价值”。
一个有趣的新工具、一个听起来很棒的副业点子，都轻易地俘获了我的注意力。我像一个收藏家，热衷于收集各种“开始”，却很少有项目能走到“完成”。每个点子在刚萌芽时都很有吸引力，但它们和工作中的“紧急”事务一样，缺乏一个统一的、指向长期目标的衡量标准。它们只是看起来有趣，而非真正重要。
这两种表现，本质上是同一个错误：我的时间和精力，被动地分配给了外部的、即时的刺激，而不是由内在的、长期的目标来主动调度。
重写算法：重要性优先 想清楚这点后，解决方案就变得异常清晰了。我需要为我的工作和生活，重新编写一套决策系统。它的核心原则只有一个：重要性永远优先。
工作端补-丁：防御性日程 划定核心时区：每天必须有 1-2 小时不容侵犯，专门留给那些“重要不紧急”的任务。这段时间，邮件通知关闭，即时通讯静音。这是为未来投资，而不是为今天救火。 建立批处理机制：对于那些“紧急不重要”的杂事，把它们圈养起来，每天在固定的时间段集中处理。就像处理垃圾邮件一样，而不是让它们每隔十分钟就弹出来一次。 业余端补-丁：战略性专注 面对无数个“想做”的念头，我会用三个筛子来过滤：
它能否构筑我的核心壁垒？ 这件事是让我变得更无可取代，还是只是另一个无关痛痒的爱好？ 它能否被杠杆放大？ 我投入的时间，能否利用媒体（写作、视频）、代码或资本，产生超越线性时间的回报？ 如果答案是否，能否自动化或放弃？ 对于那些通不过筛选的想法，果断放弃。精力是最稀缺的资源，不能慷慨地浪费在低回报的尝试上。 结语：做注意力的价值投资者 说到底，这不仅仅是关于时间管理，而是关于“注意力”的投资策略。过去，我像一个没有明确目标的散户，被市场上的各种噪音牵着鼻子走。从现在开始，我希望成为一个价值投资者，把每一份宝贵的注意力，都投给我确信在未来能产生最高复利的事情上。
图片Prompt：一个人在仓鼠轮里奋力奔跑，但这个轮子不是由铁丝构成的，而是由一圈圈发光的App图标（邮件、微信、Slack、日历提醒、社交媒体通知）组成。他跑得越快，这些图标闪烁得越频繁。而在轮子正前方不远处，有一扇敞开的门，门外是宁静的风景（代表真正的目标或深度工作），但他因为要维持轮子的转动，永远也无法踏出轮子到达那扇门。</p></div><footer class=entry-footer><span title='2025-09-13 21:06:22 +0800 +0800'>September 13, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;35 words&nbsp;·&nbsp;Miss-you</footer><a class=entry-link aria-label="post link to 我那套混乱的排序算法：从忙碌焦虑到注意力投资" href=https://miss-you.github.io/posts/20250913-energy-management/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>从副驾驶到架构师：我的AI编程协作方法论</h2></header><div class=entry-content><p>从副驾驶到架构师：我的AI编程协作方法论 在过去几年里，我更换AI编程工具的频率，几乎赶上了前端框架的迭代速度。
一开始，我像许多人一样，让GPT帮我写一个孤立的函数，感觉很神奇。后来，GitHub Copilot成了我的标配，它总能猜到我接下来要写的几行代码，尤其是在写那些重复的样板文件时。再之后，Cursor出现了，它将对话和编码更紧密地集成在编辑器里，我开始尝试让它帮我完成更复杂的任务。
我一度认为，找到那个“最强”的工具，就能一劳永逸。
然而，真正的改变，发生在我停止寻找“更好”的工具，转而开始思考如何“更好”地与它协作的那一刻。契机很偶然，只是因为Cursor的定价策略调整，我切换到了Claude Code。但我发现，尽管工具换了，我遇到的核心挑战没变，而我之前摸索出的有效工作模式，依然有效。
这让我意识到一个更根本性的问题：我们中的许多人，包括过去的我，都可能用错了力气。我们痴迷于比较不同AI的编码能力，就像在争论锤子A和锤子B哪个敲钉子更快，却忽略了我们真正要做的，是建造一座房子。
关键不在于单次挥锤的力量，而在于你是否有一张清晰的蓝图和一套高效的施工流程。
这篇文章的目的，就是分享我提炼出的这套“施工流程”——一套通用的、结构化的AI编程协作方法论。它无关乎你用的是Claude Code、Cursor，还是未来任何可能出现的新工具。它的核心是改变你与AI的协作模式：从一个偶尔寻求帮助的“使用者”，转变为一个能系统性地引导AI、共同交付高质量工作的“架构师”。
让我们从一个几乎所有开发者都会遇到的场景开始：接手一个陌生的代码库。
第一幕：AI，迷宫中的导航员 任何一个有经验的开发者都熟悉那种感觉：你被空降到一个陌生的代码库，像被扔进了一座没有地图的迷宫。文档要么不存在，要么早已过时。你只能靠着零星的注释和直觉，在成千上万行代码中摸索，试图在脑中重建一个脆弱的模型。这个过程不仅痛苦，而且极其低效，它消耗的是我们最宝贵的资源：认知带宽。
过去，这是无法避免的“功课”。但现在，我认为这是一种时间的浪费。
在与AI协作的初期，我发现它的第一个、也是最被低估的能力，不是写代码，而是读代码。与其把它看成一个初级程序员，不如把它看成一个顶级的代码分析师，一个能帮你快速绘制出迷宫地图的导航员。
让我用一个例子来说明。最近，我需要理解一个名为eino的Go语言AI框架中的ReAct机制。这是一个架构复杂的项目，如果按照传统方式，我预估需要一到两天的时间，才能理清它的核心脉络。
这一次，我没有直接一头扎进代码里。我做的第一件事，是为我的AI导航员写一份清晰的"任务简报"。我发现，一个结构化的指令远比一句模糊的"帮我看看这个项目"要有效得多。
角色 (Role): 你是谁？我告诉它：“你是一位精通Go和AI Agent的资深软件架构师。” 这为我们的对话设定了专业的基调和视角。 任务 (Task): 你要做什么？我明确指出：“你的任务是分析ReAct Agent的核心实现逻辑，并生成一份技术梳理文档。” 这定义了成功的标准。 背景 (Context): 你为什么要做这件事？我补充道：“这份文档将作为内部知识库的核心内容，帮助团队快速上手。” 这让AI理解了最终的价值。 约束 (Constraints): 你要如何交付？我给出了具体的格式要求：“文档必须包含流程梳理、接口文档和Mermaid流程图三个部分。” 这确保了输出结果是我想要的，而不是一堆无用的闲聊。 📚 借鉴总结：四要素框架是基于Google Prompt工程最佳实践等资料，结合个人理解总结提炼而成：
我把包含这四个要素的Prompt和项目代码一起交给了AI。结果是惊人的。
不到一个小时，我得到了一份完整的分析报告。它不仅精准地定位了核心入口函数（NewAgent()）、剖析了核心循环的每一步（推理、工具调用、观察、再推理），还为我生成了一张清晰的Mermaid流程图，将整个复杂的调用链路可视化。
一天的工作，一小时完成。这已经不是量级的提升，而是工作范式的改变。
这背后是什么原理？我认为关键在于两点。第一，AI拥有近乎无限的“工作记忆”，它可以同时扫描和关联成百上千个文件，在我们的大脑还在费力地跟踪两三个函数跳转时，它已经构建起了完整的调用图。第二，它强大的模式识别能力，使其能迅速识别出代码中隐藏的设计模式和架构意图，就像一个经验丰富的建筑师能从几根柱子的布局看出整栋建筑的风格。
这种导航能力，一旦掌握，可以延伸到许多场景：用它审查代码中潜在的风险，用它快速熟悉一个开源项目并参与贡献，或者用它来评估一个新技术框架的可行性。
至此，我们解决了“读”的问题。AI为我们绘制了地图，指明了方向。但真正的旅程才刚刚开始。接下来，我们需要在这张地图上建造新的东西——也就是“写”代码。
而这，恰恰是最多人掉进陷阱的地方。它引出了我们的第二个话题：如何避免随性而至的“感觉式编程”，并与AI建立一个结构化的协作流程。
第二幕：告别感觉，拥抱结构 当我们拥有了一张由AI绘制的清晰地图后，真正的建造工作开始了。也正是在这里，我们最容易走上一条歧路。
这条歧路，大家称之为“感觉式编程”（Vibe Coding）。它的诱惑力极大，因为它看起来就像是通往效率的捷径。你只需要向AI许愿：“帮我写个登录功能”，然后复制代码，粘贴，运行。如果出错了，就再许一个愿：“修复这个bug”。
这个过程，就像是雇佣了一个极其聪明但毫无经验的实习生，然后你蒙上眼睛，让他随心所欲地盖房子。你得到的是一连串的忙乱、看似进展神速的假象，以及最终一个摇摇欲坠、没人能维护的烂摊子。更糟糕的是，在这个过程中，你把最重要的思考环节外包了出去，自己的能力没有丝毫长进。
我曾掉进过这个陷阱。一次又一次的失败让我明白，问题不在于AI的能力，而在于我的协作方式。我不是在引导它，而是在放任它。
于是，我开始寻找一种更有序、更可靠的方法。
这套流程的本质，是将软件开发的经典工程原则，应用到与AI的协作中。你不再是一个简单的"使用者"，而是一个项目的"总建筑师"。
第一阶段：勘探 (Explore) 在动工之前，建筑师必须勘探地形。同样，在写任何代码之前，我和AI必须就问题和现有环境达成共识。我不会直接下令，而是会提出要求，比如：“阅读这些文件，理解当前用户认证的逻辑，但先不要写任何代码。”
这个阶段的目标，是在我和AI之间建立一个共享的、准确的上下文。这是后续所有工作的基础。
第二阶段：规划 (Plan) 这是整个流程中最关键的一步，也是最能体现开发者价值的一步。当地形勘探清楚后，我们需要一张蓝图。
我会要求AI提出一个详细的实现计划，并鼓励它思考不同方案的优劣。有时，我甚至会把同一个问题抛给不同的AI模型，像是在听取多个技术顾问的建议。最终，我会选择并敲定一个最优方案，让AI把它整理成一份清晰的、步骤化的任务列表。
一个有效的技巧是，让这份计划以技术文档或GitHub Issue的格式输出。它就像一个检查点，如果后续的“建造”阶段偏离了轨道，我们随时可以回到这份蓝图，重新校准方向。
第三阶段：建造 (Code) 有了蓝图，建造工作就变得有条不紊。这里的核心原则是：小批量、可验证。
🌟 个人改进：在基础的"小批量、可验证"原则上，我进一步增加了"自动化"和"并行化"两个维度——拆分任务后，可以启动多个AI实例并发处理独立模块，大幅提升效率；部分重复度高的任务，比如Codereview则可以集成到CI中自动化review，开发者则只需要介入AI提炼出的风险点代码。
...</p></div><footer class=entry-footer><span title='2025-08-30 15:30:00 +0800 +0800'>August 30, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;204 words&nbsp;·&nbsp;Miss-you</footer><a class=entry-link aria-label="post link to 从副驾驶到架构师：我的AI编程协作方法论" href=https://miss-you.github.io/posts/20250830-claude-code-workshop/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>拆解 ChatGPT“学习模式”Prompt：它为什么如此神奇？</h2></header><div class=entry-content><p>用了几天ChatGPT学习模式后我被震到了。拿到系统提示词，发现里面设计相当有门道——它把认知科学理论变成了可执行规则。本文完整拆解官方Prompt，分析背后的学习科学原理，并动手重构自己的版本。</p></div><footer class=entry-footer><span title='2025-08-05 10:00:00 +0800 +0800'>August 5, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;855 words&nbsp;·&nbsp;lihui</footer><a class=entry-link aria-label="post link to 拆解 ChatGPT“学习模式”Prompt：它为什么如此神奇？" href=https://miss-you.github.io/posts/20250805-study-mode-prompt/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>王者</h2></header><div class=entry-content><p>每两个月，我都要在《王者荣耀》里打够一定局数，才能保住那个王者印记。
这个印记没有任何用处。它不能换钱，不能当简历，朋友见面时也不会说"哇你王者好厉害"。但我还是要去保它。
昨天我突然意识到一件事：这就是陷阱的本质。
大多数人以为游戏公司想要的是你的钱。实际上，他们要的是你的时间。钱只是副产品。
两种游戏 虽然都叫游戏，但《王者荣耀》和《博德之门3》根本就是两种不同的东西。
《博德之门3》是产品。你买了它，玩完了，故事结束。就像一本书或一部电影。
《王者荣耀》是服务。它没有结束。永远有下一个赛季，下一个活动，下一个要保住的东西。
大多数人没有意识到这个区别。他们以为"游戏就是游戏"。但这就像把餐厅和毒品混为一谈，因为它们都能让你获得快感。
免费的陷阱 免费游戏可能是21世纪最大的商业骗局。
大多数人以为免费就是不花钱。实际上，你在付一种更昂贵的货币：时间。
假设你月薪8000，每天玩2小时王者。一个月60小时，相当于半个月工资。问题是，你得到了什么？一堆数字，一些虚拟道具，几个段位标识。
这些东西在现实世界里值多少钱？对于大部分来说，基本为零。
更糟糕的是机会成本。这60小时，你本可以学一门技能，可以读书，可以锻炼，可以和朋友聊天。任何一样都比在游戏里获得的"成就"更有价值。
但大多数人算不清这笔账。因为时间看起来是免费的。
注意力经济 这不仅仅是游戏的问题。
短视频、社交媒体、爽文小说、短剧——它们都在做同一件事：收割注意力。
它们用的是同一套方法：
即时反馈 无限滚动 算法推荐 社交压力 王者荣耀的"再来一局"，抖音的"下滑看更精彩"，爽文的"下一章要装逼了"——这些都是同一个按钮。
大多数人以为这是娱乐。实际上，这是一场争夺人类注意力的战争。而你是战场。
真正的成本 我开始用一个简单的测试来判断任何娱乐活动：
如果这个游戏/视频/内容收费每小时20元，我还会用吗？
大多数时候答案是否定的。这说明什么？说明我其实并不真正喜欢它。我只是被它的心理触发器操控了。
当我意识到这一点后，我的行为发生了变化。我卸载了一些App，取消了一些订阅。我开始把刷手机的时间，换成10分钟的冥想或20分钟的阅读。我开始为时间定价，像一个吝啬的商人一样，盘算着每一笔’时间支出’是否值得。我发现，我并没有失去什么，反而找回了生活的掌控感。
品味的腐蚀 对于想做游戏的人来说，这还有另一个危险：品味的腐蚀。
如果你天天玩设计粗糙但成瘾性强的游戏，你会开始相信"让人上瘾就是好设计"。
这就像一个想当厨师的人天天吃垃圾食品。你的味觉会退化。你会忘记什么叫好。
最好的游戏设计师都有一个共同点：他们知道什么是真正的好游戏。不是最赚钱的，不是最上瘾的，而是最值得玩的。
反击 意识到问题是第一步。第二步是行动。
对于学生来说，物理隔离最有效。把游戏设备放远一点。设置时间限制。主动寻求帮助。
对于成年人来说，关键是重新定义"免费"。没有什么是免费的。每一分钟都有价格。
对于父母来说，不要禁止，要引导。让孩子理解设计的逻辑，从玩家变成观察者。
未来 我预测，未来会出现两种人。
一种人的注意力完全被算法控制。他们以为自己在选择，实际上是在被选择。他们消费内容，但不创造价值。
另一种人会保护自己的注意力，像保护金钱一样。他们知道什么值得投入时间，什么不值得。他们是创造者。
这两种人之间的差距会越来越大。
真正的问题 但这还不是最重要的问题。
最重要的问题是：当一整代人把最好的年华献给虚拟世界时，现实世界会发生什么？
当年轻人花更多时间在游戏里"成长"，而不是在现实中成长时，会发生什么？
当人们习惯了即时满足，失去了延迟满足的能力时，会发生什么？
我不知道答案。但我知道这是人类历史上第一次面临这样的实验。
而每个沉迷于手机的人，都是这场实验的小白鼠。
问题是：你想当小白鼠，还是想当实验员？</p></div><footer class=entry-footer><span title='2025-07-27 00:17:01 +0800 +0800'>July 27, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;54 words&nbsp;·&nbsp;Miss-you</footer><a class=entry-link aria-label="post link to 王者" href=https://miss-you.github.io/posts/20250727-game-art-game-pua/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>30分钟解决Claude封号问题：程序员的终极自救指南</h2></header><div class=entry-content><p>“又被封号了？”
如果你因为使用不稳定的公共代理（机场/VPN）而频繁遭遇 Claude 封号、网络中断的困扰，那么这份指南将彻底解决你的问题。我们将一步步搭建一套专属于你的、稳定且干净的网络环境。
【你是否需要这份指南？快速诊断】 在开始之前，请先回答以下几个问题：
[ ] 我的 Claude 账号被封过，或者朋友的账号被封过。 [ ] Claude Code/Gemini CLI 非常好用，很想用，又怕被封号 [ ] 试过多个代理客户端，被规则配置搞晕了 [ ] 用公共机场/VPN，总是不稳定或突然失效 如果你勾选了任何一项，那么请继续阅读。这套方案就是为你量身定制的。
💰 预期成本 本方案需要购买一台云服务器（VPS）。 每月成本约 ￥30-60 元，大致相当于一个王者荣耀的普通皮肤，或两张抽卡游戏的月卡。这是一笔为稳定生产力工具支付的、高性价比的投资。
本指南分为两部分：
第一部分【快速上手操作手册】：如果你想立刻解决问题，请直接跟随这部分的三个步骤操作。 第二部分【原理解析与进阶】：如果你想了解“为什么这么做”，可以阅读这部分。 第一部分：快速上手操作手册 (三步走) 目标： 通过以下三步，搭建一套稳定、私人的网络环境，从此告别封号烦恼。
▶︎ 第一步：在你的电脑上安装“指挥官” (本地代理客户端) 这个工具负责智能分流网络请求。
下载并安装 Clash 客户端。 Windows 用户：搜索 Clash for Windows 或 Clash Verge。 macOS 用户：搜索 ClashX Pro 或 Clash Verge。 为什么选 Clash？ 说实话，我试过 Shadowsocks 客户端（规则太难配）、最后选了 Clash，因为规则配置直观，一看就懂。 目的：先把它装好，我们稍后会来配置它。 ▶︎ 第二步：搭建你的专属“高速通道” (自建 VPS) 这是整个流程的核心，目的是获得一个干净、固定的 IP 地址。
...</p></div><footer class=entry-footer><span title='2025-07-25 15:15:25 +0800 +0800'>July 25, 2025</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;465 words&nbsp;·&nbsp;Miss-you</footer><a class=entry-link aria-label="post link to 30分钟解决Claude封号问题：程序员的终极自救指南" href=https://miss-you.github.io/posts/20250715-how-to-pick-and-build-the-vps-svc/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://miss-you.github.io/posts/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://miss-you.github.io/>yousa Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>